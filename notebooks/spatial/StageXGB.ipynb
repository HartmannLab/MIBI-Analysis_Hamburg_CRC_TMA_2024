{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage modelling from spatial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scanpy as sc\n",
    "from joblib import Parallel, delayed\n",
    "import warnings, logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall cell features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2753385/1000358550.py:1: DtypeWarning: Columns (39,40,41,42,43,44,45,46,48,49,52,53,54,55,56,57,58,59,60,61,62,63,65,66,68) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "cell_table = pd.read_csv(\"../../data/cell_table_with_types_stage.csv\", \n",
    "                         index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_markers = ['CA9', 'CD98', 'CytC', 'MCT1', 'ASCT2', 'LDH', 'GS', 'GLS', 'ATP5A', 'CS', 'PKM2', 'GLUT1', 'ARG1', 'CPT1A', 'Ki67']\n",
    "\n",
    "# Only metabolic markers for cancer/epithelial cells\n",
    "df = cell_table.loc[cell_table.consensus == \"Cancer_cell\",metab_markers] \n",
    "meta = cell_table.loc[cell_table.consensus == \"Cancer_cell\",[\"Stage\",\"fov\"]]\n",
    "\n",
    "# A few FOVs show only few epithelial cells and might only add noise to the analysis\n",
    "sparse_epi_fovs = meta.fov.value_counts()[meta.fov.value_counts() <= 20].index\n",
    "df = df.loc[~meta.fov.isin(sparse_epi_fovs)]\n",
    "meta = meta.loc[~meta.fov.isin(sparse_epi_fovs)]\n",
    "\n",
    "# Only keep well-annotated stages\n",
    "epithelial_subset = meta[\"Stage\"].isin([\"Colon-no.\", \"pT1\", \"pT2\", \"pT3\", \"pT4\"]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to perform the prediction task on well annotated FOVs with sufficient epithelial cells.\n",
    "```python\n",
    "# Note: 13 FOVs are not annotated as healthy or to a specific cancer stage\n",
    "cell_table.loc[cell_table.fov.isin(meta.loc[~epithelial_subset].fov), \"fov\"].unique()\n",
    "\n",
    "# Additionally, 7 FOVs do not contain epithelial cells and are therefore lost\n",
    "set(cell_table.fov) - set(meta.fov)\n",
    "\n",
    "# Finally, we also exclude 27 FOVs that contain only few epithelial cells\n",
    "# The rationale is to compare on the cellular organization around the colorectal epithelium\n",
    "set(sparse_epi_fovs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage\n",
      "pT3          234\n",
      "pT4          105\n",
      "pT2           92\n",
      "pT1           19\n",
      "SCT            6\n",
      "Colon-no.      5\n",
      "Name: count, dtype: int64\n",
      "Stage\n",
      "pT3          218\n",
      "pT4           97\n",
      "pT2           85\n",
      "pT1           18\n",
      "Colon-no.      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The least represented conditions are not affected\n",
    "print(cell_table.groupby(\"fov\").first().Stage.value_counts())\n",
    "print(meta.loc[epithelial_subset].groupby(\"fov\").first().Stage.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A1a A1h A2g A2i A2q A2r A3m A4e A4n A5a A5f A5q A6b A6c A6g A6m A6p A6q A6r A7f A7p A8a A8h A8m A9o B1h B1k B2a B2b B2h B2k B2o B3c B3g B4b B4g B4m B5r B6i B6q B7c B7p B7r B8b B8d B8g B8i B8l B9c B9d B9h B9m B9n B9o C1l C2a C2f C2k C3c C3h C4a C4g C4k C5a C5k C5l C6d C8a C8h D1i D1l D1m D4c D4h D5b D5h D5k D5l D6b D6c D6k D7a D8d D8h E4e'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define which fovs will be held out for validation (outer loop)\n",
    "fov_stage_table = meta.loc[epithelial_subset].drop_duplicates().reset_index(drop=True)\n",
    "fov_inner, fov_val, y_inner, y_val = train_test_split(\n",
    "    fov_stage_table[\"fov\"], fov_stage_table[\"Stage\"], test_size=0.2, random_state=0, stratify=fov_stage_table[\"Stage\"])\n",
    "meta[\"inner\"] = meta[\"fov\"].isin(fov_inner)\n",
    "# For sanity check, the following should consistently be used as validation set\n",
    "\" \".join(fov_val.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A1d', 'A1e', 'A1l', 'A1n', 'A2e'], dtype='object', name='fov')\n",
      "Index(['A1c', 'A1m', 'A1o', 'A1p', 'A1q'], dtype='object', name='fov')\n",
      "Index(['A1i', 'A1r', 'A2b', 'A2c', 'A2l'], dtype='object', name='fov')\n",
      "Index(['A1f', 'A1k', 'A2a', 'A2d', 'A2m'], dtype='object', name='fov')\n"
     ]
    }
   ],
   "source": [
    "n_splits = 4\n",
    "\n",
    "cv_folds = StratifiedGroupKFold(n_splits=n_splits)\n",
    "for train, test in cv_folds.split(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "                                  meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "                                  groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]):\n",
    "    # All stages should be present in both train and test\n",
    "    assert len(meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[test].groupby(\"fov\")[\"Stage\"].first().unique()) == 5\n",
    "    assert len(meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[train].groupby(\"fov\")[\"Stage\"].first().unique()) == 5\n",
    "    # Print the first test FOVs\n",
    "    print(meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[test].groupby(\"fov\").first().index[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the data at the cell level to allow applications that involve processing single cells. The grouping ensures that the data is split per FOV without contamination (i.e. cells from a given FOV present both in training and testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_fov = df.copy()\n",
    "df_per_fov[\"fov\"] = meta[\"fov\"] \n",
    "df_per_fov = df_per_fov.loc[epithelial_subset].groupby(\"fov\").mean()\n",
    "meta_per_fov = meta.loc[epithelial_subset].groupby(\"fov\").first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we directly split the FOVs, for applications that involve FOV-level features. \n",
    "Note: we could generate independent folds, but the FOV distribution would not be identical.\n",
    "We choose to directly define the folds to be the same to make results more comparable.\n",
    "```Python\n",
    "cv_folds_fov = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "for train, test in cv_folds_fov.split(df_per_fov.loc[meta_per_fov[\"inner\"]],\n",
    "                                      meta_per_fov.loc[meta_per_fov[\"inner\"]][\"Stage\"]\n",
    "                                    ):\n",
    "    # All stages should be present in both train and test\n",
    "    assert len(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test][\"Stage\"].unique()) == 5\n",
    "    assert len(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[train][\"Stage\"].unique()) == 5\n",
    "    # Print the first test FOVs\n",
    "    print(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test].index[:5]) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A1d', 'A1e', 'A1l', 'A1n', 'A2e'], dtype='object', name='fov')\n",
      "Index(['A1c', 'A1m', 'A1o', 'A1p', 'A1q'], dtype='object', name='fov')\n",
      "Index(['A1i', 'A1r', 'A2b', 'A2c', 'A2l'], dtype='object', name='fov')\n",
      "Index(['A1f', 'A1k', 'A2a', 'A2d', 'A2m'], dtype='object', name='fov')\n"
     ]
    }
   ],
   "source": [
    "def conv_traintest_cells_to_fov():\n",
    "    for train, test in cv_folds.split(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "                                    meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "                                    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]):\n",
    "        test_fovs = meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[test].groupby(\"fov\").first().index\n",
    "        train_fovs = meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[train].groupby(\"fov\").first().index\n",
    "        test_fovs_ind = np.where(meta_per_fov.loc[meta_per_fov[\"inner\"]].index.isin(test_fovs))[0]\n",
    "        train_fovs_ind = np.where(meta_per_fov.loc[meta_per_fov[\"inner\"]].index.isin(train_fovs))[0]\n",
    "        yield (train_fovs_ind, test_fovs_ind)\n",
    "\n",
    "# Should work as the output of `split` method: two arrays of indices\n",
    "cv_folds_fov = [x for x in conv_traintest_cells_to_fov()]\n",
    "\n",
    "for train, test in cv_folds_fov:\n",
    "    # All stages should be present in both train and test\n",
    "    assert len(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test][\"Stage\"].unique()) == 5\n",
    "    assert len(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[train][\"Stage\"].unique()) == 5\n",
    "    # Print the first test FOVs\n",
    "    print(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test].index[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0: Baseline (most abundant label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13593358969663677"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([f1_score(LabelEncoder().fit_transform(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test][\"Stage\"]),\n",
    "                [3 for _ in range(meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test].shape[0])],\n",
    "                average=\"macro\")\n",
    "                for train, test in cv_folds_fov])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Cell type composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_proportions = cell_table.groupby(\"fov\")[\"consensus\"].value_counts().unstack().fillna(0)\n",
    "# Normalize by the number of cells in each FOV\n",
    "cell_type_proportions = cell_type_proportions.div(cell_type_proportions.sum(axis=1), axis=0)\n",
    "# Match to metadata and kept FOVs\n",
    "cell_type_proportions = cell_type_proportions.loc[meta_per_fov.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loan/miniforge3/envs/pam-keras3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [17:26:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.21614339, 0.24350877, 0.19701984, 0.22308611])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    cell_type_proportions.loc[meta_per_fov[\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta_per_fov.loc[meta_per_fov[\"inner\"]][\"Stage\"]),\n",
    "    cv=cv_folds_fov, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cell type composition, XGBoost seems appropriate.\n",
    "```Python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define models and their hyperparameters\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'LogisticRegression': LogisticRegression()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [3, 5],\n",
    "        'device': ['cuda'],\n",
    "        'random_state': [0]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['lbfgs']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "for model_name in models:\n",
    "    grid_search = GridSearchCV(models[model_name], params[model_name], cv=cv_folds_fov, scoring='f1_macro')\n",
    "    grid_search.fit(cell_type_proportions.loc[meta_per_fov[\"inner\"]], LabelEncoder().fit_transform(meta_per_fov.loc[meta_per_fov[\"inner\"]][\"Stage\"]))\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    best_scores[model_name] = grid_search.best_score_\n",
    "\n",
    "# Print the best models and their parameters\n",
    "for model in best_models.keys():\n",
    "    print(model, best_models[model])\n",
    "    print(\"Best score:\", best_scores[model])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest RandomForestClassifier(max_depth=7, n_estimators=50)\n",
      "Best score: 0.18921113795228467\n",
      "XGBoost XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=50, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "Best score: 0.22902662111995187\n",
      "SVM SVC(C=10)\n",
      "Best score: 0.16942377871729714\n",
      "LogisticRegression LogisticRegression(C=10)\n",
      "Best score: 0.15193740381482318\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold_composition(train, test, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):      \n",
    "        # Step 1: Define train and test subsets of the compositional data\n",
    "        train_composition = cell_type_proportions.loc[meta_per_fov[\"inner\"]].iloc[train]\n",
    "        test_composition = cell_type_proportions.loc[meta_per_fov[\"inner\"]].iloc[test]\n",
    "        train_meta = meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[train][\"Stage\"]\n",
    "        test_meta = meta_per_fov.loc[meta_per_fov[\"inner\"]].iloc[test][\"Stage\"]\n",
    "\n",
    "        # Step 2: Train a classifier on the training data composition to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_composition,\n",
    "                LabelEncoder().fit_transform(train_meta))\n",
    "\n",
    "        # Step 3: Predict stage of each FOV in the test data\n",
    "        preds = xgb.predict(test_composition)\n",
    "\n",
    "        # Step 4: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(test_meta), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_estimator_composition(estimators):\n",
    "    scores = [process_fold_composition(train, test, n_estimators=estimators)\n",
    "              for train, test in cv_folds_fov]\n",
    "    mean_score = np.mean(scores)\n",
    "    # Append to f1 score log file\n",
    "    with open(f\"../../data/model1_cell_composition_f1_scores.txt\", \"a\") as f:\n",
    "        f.write(f\"{estimators},{mean_score}\\n\")\n",
    "    \n",
    "    print(estimators, mean_score)\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.22646412466862742\n",
      "60 0.23237111790051587\n",
      "70 0.22481340528160249\n",
      "80 0.22185852425545932\n",
      "90 0.22652141523648733\n",
      "100 0.22402519230548182\n",
      "110 0.22149567220861638\n",
      "120 0.2361872495572352\n",
      "130 0.2347837120697448\n",
      "140 0.2352441551717641\n",
      "150 0.23573434499117085\n",
      "160 0.2428207545948951\n",
      "170 0.22214746394352586\n",
      "180 0.22200453777508428\n",
      "190 0.22108205101633283\n",
      "200 0.2199281668690276\n",
      "210 0.22177034262198053\n",
      "220 0.21963307242887645\n",
      "230 0.21963307242887645\n",
      "240 0.21544310609445325\n",
      "250 0.21993952678294126\n",
      "260 0.22110051885712914\n",
      "270 0.21993952678294126\n",
      "280 0.21743320607600433\n",
      "290 0.21662121815978286\n",
      "300 0.21662121815978286\n",
      "310 0.21851115554192702\n",
      "320 0.21772180512993505\n",
      "330 0.21851115554192702\n",
      "340 0.21851115554192702\n",
      "350 0.21641236551696796\n",
      "360 0.21751295248712016\n",
      "370 0.21641236551696796\n",
      "380 0.21751295248712016\n",
      "390 0.21751295248712016\n",
      "400 0.21751295248712016\n",
      "410 0.21672360207512825\n",
      "420 0.21672360207512825\n",
      "430 0.21672360207512825\n",
      "440 0.2165444964133374\n",
      "450 0.2165444964133374\n",
      "460 0.2165444964133374\n",
      "470 0.21863831001331002\n",
      "480 0.21863831001331002\n",
      "490 0.21863831001331002\n",
      "500 0.21456092906092905\n",
      "510 0.22120088816690756\n",
      "520 0.22120088816690756\n",
      "530 0.21826931326931326\n",
      "540 0.2173301294353926\n",
      "550 0.21826205326205325\n",
      "560 0.21826205326205325\n",
      "570 0.21826205326205325\n",
      "580 0.21826205326205325\n",
      "590 0.21826205326205325\n",
      "600 0.21826205326205325\n",
      "610 0.21826205326205325\n",
      "620 0.21826205326205325\n",
      "630 0.21826205326205325\n",
      "640 0.21826205326205325\n",
      "650 0.21825737275737275\n",
      "660 0.21729248189774508\n",
      "670 0.21822440572440574\n",
      "680 0.2144112189112189\n",
      "690 0.21437825187825188\n",
      "700 0.2144112189112189\n",
      "710 0.21362174522700839\n",
      "720 0.21362174522700839\n",
      "730 0.21362174522700839\n",
      "740 0.21362174522700839\n",
      "750 0.21363687567383605\n",
      "760 0.23060574014270052\n",
      "770 0.21363687567383605\n",
      "780 0.21439338232507954\n",
      "790 0.2144263493580466\n",
      "800 0.21439338232507954\n",
      "810 0.21439338232507954\n",
      "820 0.21439338232507954\n",
      "830 0.21439338232507954\n",
      "840 0.21618448338088647\n",
      "850 0.21332378040596306\n",
      "860 0.21618448338088647\n",
      "870 0.21618448338088647\n",
      "880 0.21618448338088647\n",
      "890 0.21618448338088647\n",
      "900 0.21618448338088647\n",
      "910 0.21618448338088647\n",
      "920 0.21618448338088647\n",
      "930 0.21618448338088647\n",
      "940 0.21539500969667597\n",
      "950 0.21618448338088647\n",
      "960 0.2184561578894031\n",
      "970 0.2184561578894031\n",
      "980 0.2184561578894031\n",
      "990 0.21832824816471919\n",
      "1000 0.217004482333784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>160</td>\n",
       "      <td>0.242821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120</td>\n",
       "      <td>0.236187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150</td>\n",
       "      <td>0.235734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140</td>\n",
       "      <td>0.235244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>0.234784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0.232371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>760</td>\n",
       "      <td>0.230606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>0.226521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.226464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.224813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    estimators     score\n",
       "11         160  0.242821\n",
       "7          120  0.236187\n",
       "10         150  0.235734\n",
       "9          140  0.235244\n",
       "8          130  0.234784\n",
       "1           60  0.232371\n",
       "71         760  0.230606\n",
       "4           90  0.226521\n",
       "0           50  0.226464\n",
       "2           70  0.224813"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallelize the hyperparameter loop | ~81mn\n",
    "Parallel(n_jobs=28)(delayed(test_estimator_composition)(r_estimators)\n",
    "                for r_estimators in np.arange(50, 1001, 10))\n",
    "\n",
    "pd.read_csv(\"../../data/model1_cell_composition_f1_scores.txt\", header=None, names=[\"estimators\", \"score\"]).sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Metabolic clusters\n",
    "See *MetabViz.ipynb* for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21137964, 0.31287193, 0.25688164, 0.19952781])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_per_fov = df.copy()\n",
    "df_per_fov[\"fov\"] = meta[\"fov\"] \n",
    "df_per_fov = df_per_fov.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].groupby(\"fov\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.23</td>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "      <td>0.369303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>440</td>\n",
       "      <td>0.360735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.13</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0.355948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.63</td>\n",
       "      <td>3</td>\n",
       "      <td>268</td>\n",
       "      <td>0.354892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>369</td>\n",
       "      <td>0.351360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.29</td>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "      <td>0.350469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.29</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>0.348103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.58</td>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "      <td>0.345388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.35</td>\n",
       "      <td>9</td>\n",
       "      <td>165</td>\n",
       "      <td>0.342340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.41</td>\n",
       "      <td>6</td>\n",
       "      <td>448</td>\n",
       "      <td>0.341682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     resolution  neighbors  estimators     score\n",
       "153        0.23          5         169  0.369303\n",
       "68         0.90          5         440  0.360735\n",
       "56         0.13         11          31  0.355948\n",
       "352        0.63          3         268  0.354892\n",
       "140        0.86          4         369  0.351360\n",
       "47         0.29          2         228  0.350469\n",
       "48         0.29          2         242  0.348103\n",
       "172        0.58          2         356  0.345388\n",
       "315        0.35          9         165  0.342340\n",
       "271        0.41          6         448  0.341682"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../../data/cluster_f1_scores.txt\").sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.23\n",
    "neighbors = 5\n",
    "estimators = 169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(train, test, n_neighbors = 30, resolution = 0.5, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        # Step 1: Define metabolic clusters on training data\n",
    "        ad = sc.AnnData(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train])\n",
    "        sc.pp.neighbors(ad, n_neighbors=n_neighbors)\n",
    "        sc.tl.leiden(ad, resolution=resolution)\n",
    "        ad.obs.leiden = ad.obs.leiden.values.astype(int)\n",
    "\n",
    "        # Step 2: Define a classifier to propagate the clusters to the test data\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "        neigh.fit(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train].values, \n",
    "                ad.obs.leiden.values)\n",
    "\n",
    "        # Step 3: Compute proportion of cells in each cluster for each FOV in the training data\n",
    "        train_fov_cluster_composition = pd.DataFrame(ad.obs.leiden.values, columns=[\"Cluster\"])\n",
    "        train_fov_cluster_composition[\"fov\"] = (\n",
    "            meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train][\"fov\"].values\n",
    "        )\n",
    "        train_fov_cluster_composition = (\n",
    "            train_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    "        )\n",
    "        # Normalize by the number of cells in each FOV\n",
    "        train_fov_cluster_composition = (\n",
    "            train_fov_cluster_composition.div(train_fov_cluster_composition.sum(axis=1), axis=0)\n",
    "        )\n",
    "\n",
    "        # Step 4: Train a classifier on the training data composition to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_fov_cluster_composition,\n",
    "                LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[train_fov_cluster_composition.index]))\n",
    "        \n",
    "        # Step 5: Predict clusters on test data\n",
    "        test_clusters = neigh.predict(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test].values)\n",
    "\n",
    "        # Step 6: Compute proportion of cells in each cluster for each FOV in the test data\n",
    "        test_fov_cluster_composition = pd.DataFrame(test_clusters, columns=[\"Cluster\"])\n",
    "        test_fov_cluster_composition[\"fov\"] = meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test][\"fov\"].values\n",
    "        test_fov_cluster_composition = test_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    "        # Normalize by the number of cells in each FOV\n",
    "        test_fov_cluster_composition = test_fov_cluster_composition.div(test_fov_cluster_composition.sum(axis=1), axis=0)\n",
    "        \n",
    "        # Ensure all clusters are covered in the testing dataframe\n",
    "        for cluster in train_fov_cluster_composition.columns:\n",
    "            if cluster not in test_fov_cluster_composition.columns:\n",
    "                test_fov_cluster_composition[cluster] = 0\n",
    "\n",
    "        # Reorder columns to match the training set\n",
    "        test_fov_cluster_composition = test_fov_cluster_composition[train_fov_cluster_composition.columns]\n",
    "\n",
    "        # Step 7: Predict stage of each FOV in the test data\n",
    "        preds = xgb.predict(test_fov_cluster_composition)\n",
    "\n",
    "        # Step 8: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[test_fov_cluster_composition.index]), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score\n",
    "    \n",
    "# Function to process a single set of hyperparameters\n",
    "def process_hyperparameters(r_resolution, r_neighbors, r_estimators):\n",
    "    r_neighbors = int(r_neighbors)\n",
    "    print(r_resolution, r_neighbors, r_estimators)\n",
    "    scores = Parallel(n_jobs=1)(delayed(process_fold)(train, \n",
    "                                                       test, \n",
    "                                                       n_neighbors=r_neighbors,\n",
    "                                                       resolution=r_resolution,\n",
    "                                                       n_estimators=r_estimators) \n",
    "                                 for train, test in cv_folds.split(\n",
    "        df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    ))\n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"[Results]  \", r_resolution, r_neighbors, r_estimators, mean_score)\n",
    "    \n",
    "    # Ensure file exists\n",
    "    if not os.path.isfile(\"../../data/cluster_f1_scores.txt\"):\n",
    "        with open(\"../../data/cluster_f1_scores.txt\", \"w\") as f:\n",
    "            f.write(\"resolution,neighbors,estimators,score\\n\")\n",
    "\n",
    "    # Append to f1 score log file\n",
    "    with open(f\"../../data/cluster_f1_scores.txt\", \"a\") as f:\n",
    "        f.write(f\"{r_resolution},{r_neighbors},{r_estimators},{mean_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 17:29:30.000384: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 17:29:30.022882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 17:29:30.174898: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 17:29:30.195231: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 17:29:30.524630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-01-15 17:29:30.700512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-01-15 17:29:30.984135: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 17:29:31.002465: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 17:29:31.004415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 17:29:31.025007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 17:29:31.542385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-01-15 17:29:31.554552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36930323414085386\n"
     ]
    }
   ],
   "source": [
    "scores = Parallel(n_jobs=-1)(delayed(process_fold)(train, \n",
    "                                                    test, \n",
    "                                                    n_neighbors=neighbors,\n",
    "                                                    resolution=res,\n",
    "                                                    n_estimators=estimators) \n",
    "                                 for train, test in cv_folds.split(\n",
    "        df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    )) # This should confirm the model selection estimates\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: MISTy cell type features\n",
    "Will need to be re-run with `zoi` set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juxtaview.40_l.Cancer_cell_Cancer_cell</th>\n",
       "      <th>juxtaview.40_l.Endothelial_cell_Endothelial_cell</th>\n",
       "      <th>paraview.100_p.Endothelial_cell_Endothelial_cell</th>\n",
       "      <th>paraview.100_p.CAF_CAF</th>\n",
       "      <th>paraview.100_p.Cancer_cell_Cancer_cell</th>\n",
       "      <th>juxtaview.40_l.CAF_CAF</th>\n",
       "      <th>paraview.100_p.Monocyte_Monocyte</th>\n",
       "      <th>juxtaview.40_l.Monocyte_Monocyte</th>\n",
       "      <th>paraview.100_p.Other_immune_cell_Other_immune_cell</th>\n",
       "      <th>paraview.100_p.CD68_Macrophage_CD68_Macrophage</th>\n",
       "      <th>...</th>\n",
       "      <th>paraview.100_p.Endothelial_cell_CD68_Macrophage</th>\n",
       "      <th>paraview.100_p.Other_immune_cell_CD163_Macrophage</th>\n",
       "      <th>paraview.100_p.CAF_Monocyte</th>\n",
       "      <th>juxtaview.40_l.Other_immune_cell_CD8_Tcell</th>\n",
       "      <th>paraview.100_p.CAF_CD4_Tcell</th>\n",
       "      <th>paraview.100_p.Monocyte_Endothelial_cell</th>\n",
       "      <th>paraview.100_p.CD4_Tcell_Monocyte</th>\n",
       "      <th>paraview.100_p.CAF_CD68_Macrophage</th>\n",
       "      <th>paraview.100_p.Cancer_cell_CD4_Tcell</th>\n",
       "      <th>paraview.100_p.CD4_Tcell_Other_immune_cell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1a</th>\n",
       "      <td>3.241289</td>\n",
       "      <td>1.869391</td>\n",
       "      <td>1.735802</td>\n",
       "      <td>1.214244</td>\n",
       "      <td>1.510572</td>\n",
       "      <td>2.906951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.686409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1c</th>\n",
       "      <td>3.372725</td>\n",
       "      <td>3.330195</td>\n",
       "      <td>1.714173</td>\n",
       "      <td>1.193790</td>\n",
       "      <td>2.344175</td>\n",
       "      <td>3.171733</td>\n",
       "      <td>0.937414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.217521</td>\n",
       "      <td>1.431484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1d</th>\n",
       "      <td>3.140940</td>\n",
       "      <td>2.861029</td>\n",
       "      <td>2.328312</td>\n",
       "      <td>1.404295</td>\n",
       "      <td>2.072094</td>\n",
       "      <td>2.471668</td>\n",
       "      <td>1.100926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.132901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1e</th>\n",
       "      <td>2.847571</td>\n",
       "      <td>3.204835</td>\n",
       "      <td>1.515047</td>\n",
       "      <td>1.959971</td>\n",
       "      <td>1.997507</td>\n",
       "      <td>3.088748</td>\n",
       "      <td>3.116230</td>\n",
       "      <td>1.486980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.383975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1f</th>\n",
       "      <td>2.902234</td>\n",
       "      <td>3.088106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.361394</td>\n",
       "      <td>1.301067</td>\n",
       "      <td>1.574763</td>\n",
       "      <td>1.309559</td>\n",
       "      <td>1.584863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.593865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.442211</td>\n",
       "      <td>1.223243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.210359</td>\n",
       "      <td>2.400164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3c</th>\n",
       "      <td>3.314948</td>\n",
       "      <td>3.053053</td>\n",
       "      <td>1.040383</td>\n",
       "      <td>2.578936</td>\n",
       "      <td>2.574410</td>\n",
       "      <td>3.453385</td>\n",
       "      <td>1.671570</td>\n",
       "      <td>2.109663</td>\n",
       "      <td>3.133494</td>\n",
       "      <td>2.190319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3e</th>\n",
       "      <td>1.312875</td>\n",
       "      <td>1.099634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.214136</td>\n",
       "      <td>2.492264</td>\n",
       "      <td>2.139975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4a</th>\n",
       "      <td>3.246438</td>\n",
       "      <td>2.904361</td>\n",
       "      <td>1.910934</td>\n",
       "      <td>1.010343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.716840</td>\n",
       "      <td>2.164491</td>\n",
       "      <td>2.737081</td>\n",
       "      <td>1.948477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4d</th>\n",
       "      <td>2.924364</td>\n",
       "      <td>1.503004</td>\n",
       "      <td>1.256012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.809912</td>\n",
       "      <td>2.678005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.294258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4e</th>\n",
       "      <td>2.844623</td>\n",
       "      <td>1.632119</td>\n",
       "      <td>1.559501</td>\n",
       "      <td>1.445133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.096204</td>\n",
       "      <td>2.005099</td>\n",
       "      <td>2.200286</td>\n",
       "      <td>1.357291</td>\n",
       "      <td>1.736867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        juxtaview.40_l.Cancer_cell_Cancer_cell  \\\n",
       "sample                                           \n",
       "A1a                                   3.241289   \n",
       "A1c                                   3.372725   \n",
       "A1d                                   3.140940   \n",
       "A1e                                   2.847571   \n",
       "A1f                                   2.902234   \n",
       "...                                        ...   \n",
       "E3c                                   3.314948   \n",
       "E3e                                   1.312875   \n",
       "E4a                                   3.246438   \n",
       "E4d                                   2.924364   \n",
       "E4e                                   2.844623   \n",
       "\n",
       "        juxtaview.40_l.Endothelial_cell_Endothelial_cell  \\\n",
       "sample                                                     \n",
       "A1a                                             1.869391   \n",
       "A1c                                             3.330195   \n",
       "A1d                                             2.861029   \n",
       "A1e                                             3.204835   \n",
       "A1f                                             3.088106   \n",
       "...                                                  ...   \n",
       "E3c                                             3.053053   \n",
       "E3e                                             1.099634   \n",
       "E4a                                             2.904361   \n",
       "E4d                                             1.503004   \n",
       "E4e                                             1.632119   \n",
       "\n",
       "        paraview.100_p.Endothelial_cell_Endothelial_cell  \\\n",
       "sample                                                     \n",
       "A1a                                             1.735802   \n",
       "A1c                                             1.714173   \n",
       "A1d                                             2.328312   \n",
       "A1e                                             1.515047   \n",
       "A1f                                             0.000000   \n",
       "...                                                  ...   \n",
       "E3c                                             1.040383   \n",
       "E3e                                             0.000000   \n",
       "E4a                                             1.910934   \n",
       "E4d                                             1.256012   \n",
       "E4e                                             1.559501   \n",
       "\n",
       "        paraview.100_p.CAF_CAF  paraview.100_p.Cancer_cell_Cancer_cell  \\\n",
       "sample                                                                   \n",
       "A1a                   1.214244                                1.510572   \n",
       "A1c                   1.193790                                2.344175   \n",
       "A1d                   1.404295                                2.072094   \n",
       "A1e                   1.959971                                1.997507   \n",
       "A1f                   2.361394                                1.301067   \n",
       "...                        ...                                     ...   \n",
       "E3c                   2.578936                                2.574410   \n",
       "E3e                   0.000000                                0.000000   \n",
       "E4a                   1.010343                                0.000000   \n",
       "E4d                   0.000000                                0.984475   \n",
       "E4e                   1.445133                                0.000000   \n",
       "\n",
       "        juxtaview.40_l.CAF_CAF  paraview.100_p.Monocyte_Monocyte  \\\n",
       "sample                                                             \n",
       "A1a                   2.906951                          0.000000   \n",
       "A1c                   3.171733                          0.937414   \n",
       "A1d                   2.471668                          1.100926   \n",
       "A1e                   3.088748                          3.116230   \n",
       "A1f                   1.574763                          1.309559   \n",
       "...                        ...                               ...   \n",
       "E3c                   3.453385                          1.671570   \n",
       "E3e                   0.000000                          1.214136   \n",
       "E4a                   1.716840                          2.164491   \n",
       "E4d                   0.000000                          1.809912   \n",
       "E4e                   3.096204                          2.005099   \n",
       "\n",
       "        juxtaview.40_l.Monocyte_Monocyte  \\\n",
       "sample                                     \n",
       "A1a                             0.000000   \n",
       "A1c                             0.000000   \n",
       "A1d                             0.000000   \n",
       "A1e                             1.486980   \n",
       "A1f                             1.584863   \n",
       "...                                  ...   \n",
       "E3c                             2.109663   \n",
       "E3e                             2.492264   \n",
       "E4a                             2.737081   \n",
       "E4d                             2.678005   \n",
       "E4e                             2.200286   \n",
       "\n",
       "        paraview.100_p.Other_immune_cell_Other_immune_cell  \\\n",
       "sample                                                       \n",
       "A1a                                              1.686409    \n",
       "A1c                                              2.217521    \n",
       "A1d                                              2.132901    \n",
       "A1e                                              0.000000    \n",
       "A1f                                              0.000000    \n",
       "...                                                   ...    \n",
       "E3c                                              3.133494    \n",
       "E3e                                              2.139975    \n",
       "E4a                                              1.948477    \n",
       "E4d                                              0.000000    \n",
       "E4e                                              1.357291    \n",
       "\n",
       "        paraview.100_p.CD68_Macrophage_CD68_Macrophage  ...  \\\n",
       "sample                                                  ...   \n",
       "A1a                                           0.000000  ...   \n",
       "A1c                                           1.431484  ...   \n",
       "A1d                                           0.000000  ...   \n",
       "A1e                                           0.000000  ...   \n",
       "A1f                                           2.593865  ...   \n",
       "...                                                ...  ...   \n",
       "E3c                                           2.190319  ...   \n",
       "E3e                                           0.000000  ...   \n",
       "E4a                                           0.000000  ...   \n",
       "E4d                                           0.000000  ...   \n",
       "E4e                                           1.736867  ...   \n",
       "\n",
       "        paraview.100_p.Endothelial_cell_CD68_Macrophage  \\\n",
       "sample                                                    \n",
       "A1a                                            0.000000   \n",
       "A1c                                            0.000000   \n",
       "A1d                                            0.000000   \n",
       "A1e                                            1.383975   \n",
       "A1f                                            0.000000   \n",
       "...                                                 ...   \n",
       "E3c                                            0.000000   \n",
       "E3e                                            0.000000   \n",
       "E4a                                            0.000000   \n",
       "E4d                                            2.294258   \n",
       "E4e                                            0.000000   \n",
       "\n",
       "        paraview.100_p.Other_immune_cell_CD163_Macrophage  \\\n",
       "sample                                                      \n",
       "A1a                                                   0.0   \n",
       "A1c                                                   0.0   \n",
       "A1d                                                   0.0   \n",
       "A1e                                                   0.0   \n",
       "A1f                                                   0.0   \n",
       "...                                                   ...   \n",
       "E3c                                                   0.0   \n",
       "E3e                                                   0.0   \n",
       "E4a                                                   0.0   \n",
       "E4d                                                   0.0   \n",
       "E4e                                                   0.0   \n",
       "\n",
       "        paraview.100_p.CAF_Monocyte  \\\n",
       "sample                                \n",
       "A1a                             0.0   \n",
       "A1c                             0.0   \n",
       "A1d                             0.0   \n",
       "A1e                             0.0   \n",
       "A1f                             0.0   \n",
       "...                             ...   \n",
       "E3c                             0.0   \n",
       "E3e                             0.0   \n",
       "E4a                             0.0   \n",
       "E4d                             0.0   \n",
       "E4e                             0.0   \n",
       "\n",
       "        juxtaview.40_l.Other_immune_cell_CD8_Tcell  \\\n",
       "sample                                               \n",
       "A1a                                       0.000000   \n",
       "A1c                                       0.000000   \n",
       "A1d                                       0.000000   \n",
       "A1e                                       0.000000   \n",
       "A1f                                       0.942197   \n",
       "...                                            ...   \n",
       "E3c                                       0.000000   \n",
       "E3e                                       0.000000   \n",
       "E4a                                       0.973520   \n",
       "E4d                                       0.000000   \n",
       "E4e                                       0.000000   \n",
       "\n",
       "        paraview.100_p.CAF_CD4_Tcell  \\\n",
       "sample                                 \n",
       "A1a                              0.0   \n",
       "A1c                              0.0   \n",
       "A1d                              0.0   \n",
       "A1e                              0.0   \n",
       "A1f                              0.0   \n",
       "...                              ...   \n",
       "E3c                              0.0   \n",
       "E3e                              0.0   \n",
       "E4a                              0.0   \n",
       "E4d                              0.0   \n",
       "E4e                              0.0   \n",
       "\n",
       "        paraview.100_p.Monocyte_Endothelial_cell  \\\n",
       "sample                                             \n",
       "A1a                                     0.000000   \n",
       "A1c                                     0.000000   \n",
       "A1d                                     0.000000   \n",
       "A1e                                     0.000000   \n",
       "A1f                                     1.442211   \n",
       "...                                          ...   \n",
       "E3c                                     1.916585   \n",
       "E3e                                     0.000000   \n",
       "E4a                                     0.000000   \n",
       "E4d                                     0.000000   \n",
       "E4e                                     0.000000   \n",
       "\n",
       "        paraview.100_p.CD4_Tcell_Monocyte  paraview.100_p.CAF_CD68_Macrophage  \\\n",
       "sample                                                                          \n",
       "A1a                              1.588098                                 0.0   \n",
       "A1c                              0.000000                                 0.0   \n",
       "A1d                              0.000000                                 0.0   \n",
       "A1e                              0.000000                                 0.0   \n",
       "A1f                              1.223243                                 0.0   \n",
       "...                                   ...                                 ...   \n",
       "E3c                              0.000000                                 0.0   \n",
       "E3e                              0.000000                                 0.0   \n",
       "E4a                              0.000000                                 0.0   \n",
       "E4d                              0.000000                                 0.0   \n",
       "E4e                              0.000000                                 0.0   \n",
       "\n",
       "        paraview.100_p.Cancer_cell_CD4_Tcell  \\\n",
       "sample                                         \n",
       "A1a                                 0.000000   \n",
       "A1c                                 0.000000   \n",
       "A1d                                 0.000000   \n",
       "A1e                                 0.000000   \n",
       "A1f                                 1.210359   \n",
       "...                                      ...   \n",
       "E3c                                 0.000000   \n",
       "E3e                                 0.000000   \n",
       "E4a                                 0.000000   \n",
       "E4d                                 0.000000   \n",
       "E4e                                 0.000000   \n",
       "\n",
       "        paraview.100_p.CD4_Tcell_Other_immune_cell  \n",
       "sample                                              \n",
       "A1a                                       0.000000  \n",
       "A1c                                       0.000000  \n",
       "A1d                                       0.000000  \n",
       "A1e                                       0.000000  \n",
       "A1f                                       2.400164  \n",
       "...                                            ...  \n",
       "E3c                                       0.000000  \n",
       "E3e                                       0.000000  \n",
       "E4a                                       0.000000  \n",
       "E4d                                       0.000000  \n",
       "E4e                                       0.000000  \n",
       "\n",
       "[463 rows x 100 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misty_features = pd.read_csv(\"../../data/misty_lineage_features.csv\", index_col=0)\n",
    "# Subset to top 100 most common features\n",
    "misty_features.iloc[:,np.argsort(-np.sum(misty_features > 0))[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold_misty(train, test, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        # Define correct FOV-level data\n",
    "        \n",
    "        # Step 4: Train a classifier on the training data to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_df,\n",
    "                LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[train]))\n",
    "        \n",
    "        # # Step 7: Predict stage of each FOV in the test data\n",
    "        test_df = df_misty.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[test]\n",
    "        preds = xgb.predict(test_df)\n",
    "\n",
    "        # # Step 8: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[test]), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Kasumi metabolic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Morphological features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTy duplicated per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join meta and misty features with FOV alignment\n",
    "misty_features_per_cell = (\n",
    "    meta\n",
    "    .set_index(\"fov\")\n",
    "    .join(misty_features, how=\"left\")\n",
    "    .drop([\"Stage\", \"inner\"], axis=\"columns\")\n",
    ")\n",
    "\n",
    "# Combine with original dataframe\n",
    "df_misty = pd.concat(\n",
    "    [df.reset_index(drop=True), \n",
    "     misty_features_per_cell.reset_index(drop=True)], \n",
    "    axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA9</th>\n",
       "      <th>CD98</th>\n",
       "      <th>CytC</th>\n",
       "      <th>MCT1</th>\n",
       "      <th>ASCT2</th>\n",
       "      <th>LDH</th>\n",
       "      <th>GS</th>\n",
       "      <th>GLS</th>\n",
       "      <th>ATP5A</th>\n",
       "      <th>CS</th>\n",
       "      <th>...</th>\n",
       "      <th>juxtaview.40_l.NK_cell_B_cell</th>\n",
       "      <th>juxtaview.40_l.CD68_Macrophage_B_cell</th>\n",
       "      <th>juxtaview.40_l.CD8_Tcell_B_cell</th>\n",
       "      <th>juxtaview.40_l.Endothelial_cell_B_cell</th>\n",
       "      <th>juxtaview.40_l.CD4_Tcell_B_cell</th>\n",
       "      <th>juxtaview.40_l.Monocyte_B_cell</th>\n",
       "      <th>juxtaview.40_l.CD163_Macrophage_B_cell</th>\n",
       "      <th>juxtaview.40_l.APC_B_cell</th>\n",
       "      <th>juxtaview.40_l.T_reg_cell_B_cell</th>\n",
       "      <th>juxtaview.40_l.B_cell_B_cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.045864</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.044260</td>\n",
       "      <td>0.089495</td>\n",
       "      <td>0.097397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.106513</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.024809</td>\n",
       "      <td>0.061641</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>0.079685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113299</td>\n",
       "      <td>0.034138</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.028260</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.022929</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>0.045860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.128277</td>\n",
       "      <td>0.040913</td>\n",
       "      <td>0.030368</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.032329</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.063046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107682</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.020924</td>\n",
       "      <td>0.117576</td>\n",
       "      <td>0.035627</td>\n",
       "      <td>0.028709</td>\n",
       "      <td>0.055070</td>\n",
       "      <td>0.125172</td>\n",
       "      <td>0.104851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 398 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CA9      CD98      CytC      MCT1     ASCT2       LDH        GS  \\\n",
       "0  0.021289  0.006393  0.015713  0.000193  0.045864  0.013713  0.024070   \n",
       "1  0.014578  0.008831  0.106513  0.002774  0.028734  0.002855  0.024809   \n",
       "2  0.113299  0.034138  0.011429  0.001506  0.028260  0.013809  0.009312   \n",
       "3  0.128277  0.040913  0.030368  0.005280  0.034091  0.032231  0.008779   \n",
       "4  0.107682  0.070130  0.098551  0.020924  0.117576  0.035627  0.028709   \n",
       "\n",
       "        GLS     ATP5A        CS  ...  juxtaview.40_l.NK_cell_B_cell  \\\n",
       "0  0.044260  0.089495  0.097397  ...                            0.0   \n",
       "1  0.061641  0.063325  0.079685  ...                            0.0   \n",
       "2  0.022929  0.006431  0.045860  ...                            0.0   \n",
       "3  0.032329  0.026225  0.063046  ...                            0.0   \n",
       "4  0.055070  0.125172  0.104851  ...                            0.0   \n",
       "\n",
       "   juxtaview.40_l.CD68_Macrophage_B_cell  juxtaview.40_l.CD8_Tcell_B_cell  \\\n",
       "0                                    0.0                              0.0   \n",
       "1                                    0.0                              0.0   \n",
       "2                                    0.0                              0.0   \n",
       "3                                    0.0                              0.0   \n",
       "4                                    0.0                              0.0   \n",
       "\n",
       "   juxtaview.40_l.Endothelial_cell_B_cell  juxtaview.40_l.CD4_Tcell_B_cell  \\\n",
       "0                                     0.0                              0.0   \n",
       "1                                     0.0                              0.0   \n",
       "2                                     0.0                              0.0   \n",
       "3                                     0.0                              0.0   \n",
       "4                                     0.0                              0.0   \n",
       "\n",
       "   juxtaview.40_l.Monocyte_B_cell  juxtaview.40_l.CD163_Macrophage_B_cell  \\\n",
       "0                             0.0                                     0.0   \n",
       "1                             0.0                                     0.0   \n",
       "2                             0.0                                     0.0   \n",
       "3                             0.0                                     0.0   \n",
       "4                             0.0                                     0.0   \n",
       "\n",
       "   juxtaview.40_l.APC_B_cell  juxtaview.40_l.T_reg_cell_B_cell  \\\n",
       "0                        0.0                               0.0   \n",
       "1                        0.0                               0.0   \n",
       "2                        0.0                               0.0   \n",
       "3                        0.0                               0.0   \n",
       "4                        0.0                               0.0   \n",
       "\n",
       "   juxtaview.40_l.B_cell_B_cell  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "\n",
       "[5 rows x 398 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262188, 398)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misty_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misty_features_per_cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(meta.fov.unique()) - set(misty_features.index.to_list()) # SCT samples are listed in meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(misty_features.index.to_list()) - set(meta.fov.unique()) # Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.fov.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(misty_features.index.to_list()) - set(meta.fov.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold_misty(train, test, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        train_df = df_misty.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[train]\n",
    "        \n",
    "        # Step 4: Train a classifier on the training data to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_df,\n",
    "                LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[train]))\n",
    "        \n",
    "        # # Step 7: Predict stage of each FOV in the test data\n",
    "        test_df = df_misty.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[test]\n",
    "        preds = xgb.predict(test_df)\n",
    "\n",
    "        # # Step 8: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[test]), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in cv_folds.split(\n",
    "        df_misty.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    ):\n",
    "    process_fold_misty(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Parallel(n_jobs=-1)(delayed(process_fold_misty)(train, \n",
    "                                                    test, \n",
    "                                                    n_estimators=estimators) \n",
    "                                 for train, test in cv_folds.split(\n",
    "        df_misty.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    ))\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [process_fold_misty(train, test, n_estimators=300)\n",
    "          for train, test in cv_folds.split(\n",
    "        df_misty.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    )]\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold_misty_features_per_cell(train, test, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        train_df = misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[train]\n",
    "        \n",
    "        # Step 4: Train a classifier on the training data to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_df,\n",
    "                LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[train]))\n",
    "        \n",
    "        # # Step 7: Predict stage of each FOV in the test data\n",
    "        test_df = misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[test]\n",
    "        preds = xgb.predict(test_df)\n",
    "\n",
    "        # # Step 8: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[test]), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [process_fold_misty_features_per_cell(train, test, n_estimators=220)\n",
    "          for train, test in cv_folds.split(\n",
    "        misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    )]\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimators in np.arange(50, 1001, 200):\n",
    "    scores = [process_fold_misty_features_per_cell(train, test, n_estimators=estimators)\n",
    "              for train, test in cv_folds.split(\n",
    "            misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "            meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "            groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "        )]\n",
    "    mean_score = np.mean(scores)\n",
    "    print(estimators, mean_score)\n",
    "    # Append to f1 score log file\n",
    "    with open(f\"../../data/misty_f1_scores.txt\", \"a\") as f:\n",
    "        f.write(f\"{estimators},{mean_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_estimator_misty_features_per_cell(estimators):\n",
    "    scores = [process_fold_misty_features_per_cell(train, test, n_estimators=estimators)\n",
    "          for train, test in cv_folds.split(\n",
    "        misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    )]\n",
    "    mean_score = np.mean(scores)\n",
    "    # Append to f1 score log file\n",
    "    with open(f\"../../data/misty_f1_scores.txt\", \"a\") as f:\n",
    "        f.write(f\"{estimators},{mean_score}\\n\")\n",
    "    \n",
    "    print(estimators, mean_score)\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize the hyperparameter loop | ~81mn\n",
    "Parallel(n_jobs=28)(delayed(test_estimator_misty_features_per_cell)(r_estimators)\n",
    "                for r_estimators in np.arange(50, 1001, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../../data/misty_f1_scores.txt\", header=None, names=[\"estimators\", \"score\"]).sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df, threshold=0.8):\n",
    "    # Calculate the coefficient of variation for each column\n",
    "    coef_var = df.std() / df.mean()\n",
    "    \n",
    "    # Sort columns by coefficient of variation in descending order\n",
    "    sorted_columns = coef_var.sort_values(ascending=False).index\n",
    "    \n",
    "    # Compute the full pairwise correlation matrix\n",
    "    corr_matrix = df.corr()\n",
    "    \n",
    "    # Initialize a list to keep track of selected columns\n",
    "    selected_columns = []\n",
    "    \n",
    "    # Initialize a set to keep track of columns to be dropped\n",
    "    dropped_columns = set()\n",
    "    \n",
    "    # Iterate over sorted columns\n",
    "    for col in sorted_columns:\n",
    "        if col not in dropped_columns:\n",
    "            selected_columns.append(col)\n",
    "            # Drop columns that are highly correlated with the current column\n",
    "            dropped_columns.update(corr_matrix.index[corr_matrix[col].abs() > threshold].tolist())\n",
    "    \n",
    "    # Return the dataframe with selected columns\n",
    "    return df[selected_columns]\n",
    "\n",
    "uncorr_misty_features_per_cell = transform_features(misty_features_per_cell, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold_uncorr_misty_features_per_cell(train, test, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        train_df = uncorr_misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[train]\n",
    "        \n",
    "        # Step 4: Train a classifier on the training data to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_df,\n",
    "                LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[train]))\n",
    "        \n",
    "        # # Step 7: Predict stage of each FOV in the test data\n",
    "        test_df = uncorr_misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()].iloc[test]\n",
    "        preds = xgb.predict(test_df)\n",
    "\n",
    "        # # Step 8: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[test]), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [process_fold_uncorr_misty_features_per_cell(train, test, n_estimators=300)\n",
    "          for train, test in cv_folds.split(\n",
    "        uncorr_misty_features_per_cell.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"].to_list()],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    )]\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad('../../data/adata_consensus_cell_types.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functional_and_metab = ['CA9', 'CD98', 'CytC', 'MSH2', 'MCT1', 'ASCT2',\n",
    "       'LDH', 'STING1', 'GS', 'GLS', 'ATP5A', 'CS', 'PKM2', 'GLUT1', 'MSH6', 'ARG1', 'CPT1A', 'Ki67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rows by cell type and compute median expression\n",
    "df = adata.obs.loc[:,all_functional_and_metab]\n",
    "df[\"cell_type\"] = adata.obs[\"annotation_consensus\"].values\n",
    "df = df.groupby(\"cell_type\").median().T\n",
    "df = df.drop(\"Unclear\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tumor stage\n",
    "clini = pd.read_csv(\"../../data/summary_clinical_data_modified.csv\", index_col=2)\n",
    "adata.obs = adata.obs.merge(clini, left_on=\"fov\", right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pam-keras3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
