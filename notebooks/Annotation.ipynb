{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyFlowSOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the relevant libraries for doing the analysis (there are probably still too many that you do not need)\n",
    "import pandas as pd\n",
    "from pyFlowSOM import map_data_to_nodes, som\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from skimage.io  import imread, imsave\n",
    "import skimage.io\n",
    "import anndata as ad\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import warnings\n",
    "import shutil\n",
    "import math\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the base directory\n",
    "base_dir = \"/data/preprocessing\"\n",
    "\n",
    "#set up the directory with the cell tables after running deepcell or cellpose\n",
    "cell_table_dir = base_dir \n",
    "\n",
    "#set up the directory for saving the plots of this notebook\n",
    "preprocessing_python_dir = os.path.join(base_dir, \"annotations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cell size normalized table\n",
    "df = pd.read_csv(os.path.join(cell_table_dir,'cell_table_transformed.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the names of the columns in order to define the relevant channels\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gating approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant columns for the first comparison\n",
    "columns_to_compare = ['SMA', 'CD31', 'CD163', 'CD68', 'CD8', 'CD45',\n",
    "       'PanCK', 'MPO', 'CD7']\n",
    "\n",
    "# Create a new column to store the result of the comparison\n",
    "df['highest_value_column'] = df[columns_to_compare].idxmax(axis=1)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns for second comparison using the highest_value_column to filter for certain rows\n",
    "columns_to_compare = [\"CD3e\", \"CD8\", 'CD7', \"CD14\", \"MPO\",'CD20', 'CD68', \"CD163\", \"HLADRa\"]\n",
    "\n",
    "# Check if \"highest_value_column\" is \"CD45\", if yes, compare the specified columns\n",
    "mask_cd45 = df['highest_value_column'] == 'CD45'\n",
    "df.loc[mask_cd45, 'type'] = df.loc[mask_cd45, columns_to_compare].idxmax(axis=1)\n",
    "\n",
    "# For rows not labeled CD45, copy the existing label from \"highest_value_column\" to the new column\n",
    "df.loc[~mask_cd45, 'type'] = df.loc[~mask_cd45, 'highest_value_column']\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns for second comparison using the new_column to filter for certain rows\n",
    "columns_to_compare = [\"CD4\", \"CD8\", 'CD7']\n",
    "\n",
    "# Check if \"highest_value_column\" is \"CD45\", if yes, compare the specified columns\n",
    "mask_cd45 = df['type'] == 'CD3e'\n",
    "df.loc[mask_cd45, 'cell_type'] = df.loc[mask_cd45, columns_to_compare].idxmax(axis=1).str.replace('.tiff', '')\n",
    "\n",
    "# For rows not labeled CD45, copy the existing label from \"highest_value_column\" to the new column\n",
    "df.loc[~mask_cd45, 'cell_type'] = df.loc[~mask_cd45, 'type']\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows you need for the mantis viewer\n",
    "selected_columns = df[[\"fov\", \"label\", \"cell_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a CSV file without a header so that i can be loaded in mantis viewer\n",
    "os.makedirs(preprocessing_python_dir, exist_ok=True)\n",
    "selected_columns.to_csv(os.path.join(preprocessing_python_dir, 'gating_types.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns.cell_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap visualisation\n",
    "# Specify the columns for the heatmap\n",
    "columns_for_heatmap = ['SMA', 'CD4', 'CD31', 'CD163', 'CD68', 'CD8', 'CD3e', 'HLADRa', 'CD14', 'CD45',\n",
    "       'PanCK', 'MPO', 'CD7', 'CD20', 'DCN'] # Replace with your actual column names\n",
    "\n",
    "# Create a pivot table to prepare data for the heatmap\n",
    "heatmap_data = df.pivot_table(index='cell_type', values=columns_for_heatmap)\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Heatmap for Categories from cell_type\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Categories\")\n",
    "plt.show()\n",
    "plt.savefig(os.path.join(preprocessing_python_dir, 'heatmap.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpatialSort annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format expression table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_cols = ['file_id',\"CD4\",\"CD8\",\"CD3e\",\"FoxP3\",\"SMA\",\"CD31\",\"CD45\",\"CD68\",\"CD163\",\"CD7\",\"Vimentin\",\"PanCK\",\"MPO\",\"DCN\",\"CD20\",\"HLADRa\",\"CD14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fov\"] = df[\"fov\"].astype(\"category\")\n",
    "\n",
    "new_categories_dict = {g: i for (i,g) in enumerate(df[\"fov\"].cat.categories)}\n",
    "print(new_categories_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"file_id\"] = df[\"fov\"].cat.rename_categories(new_categories_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[lineage_cols].to_csv(os.path.join(preprocessing_python_dir, 'ssort_expression.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format location table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"file_id\", \"centroid-0\", \"centroid-1\"]].to_csv(os.path.join(preprocessing_python_dir, 'ssort_location.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format neighborhood table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_pairs(id, thr):\n",
    "    subdata = df.loc[df[\"file_id\"] == id]\n",
    "    distvec = pdist(subdata[[\"centroid-0\", \"centroid-1\"]])\n",
    "    distid = [(i,j) for i in range(subdata.shape[0]) for j in range(subdata.shape[0]) if i < j]\n",
    "    return [(id, i[0], i[1]) for (i,j) in zip(distid, distvec) if j < thr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distthr = 70 # Below 50 pixels in both x and y\n",
    "all_inter = pd.concat([pd.DataFrame(get_dist_pairs(id, distthr)) for id in df[\"file_id\"].unique()])\n",
    "all_inter.columns = [\"file_id\", \"0\", \"1\"]\n",
    "all_inter.to_csv(os.path.join(preprocessing_python_dir, 'ssort_relation.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format marker table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read proposed table\n",
    "stringent_matrix_raw = pd.read_csv(os.path.join(preprocessing_python_dir, \n",
    "                                                'scyan_clustering_stringent.csv'), sep = \";\")\n",
    "stringent_matrix = stringent_matrix_raw.iloc[:,3:-1]\n",
    "# Invert -1 and 0 (0 should be low and -1 unknown)\n",
    "stringent_matrix.to_numpy()[stringent_matrix_raw.iloc[:,3:-1] == -1] = 0\n",
    "stringent_matrix.to_numpy()[stringent_matrix_raw.iloc[:,3:-1] == 0] = -1\n",
    "stringent_matrix.to_csv(os.path.join(preprocessing_python_dir, 'ssort_prior_strict.csv'),\n",
    "                         index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate how the matrix is loaded by SpatialSort\n",
    "# stm = pd.read_csv(os.path.join(preprocessing_python_dir, 'ssort_prior_strict.csv')).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read proposed table\n",
    "permissive_matrix_raw = pd.read_csv(os.path.join(preprocessing_python_dir, \n",
    "                                                'scyan_clustering_less_stringent.csv'), \n",
    "                                                sep = \";\")\n",
    "permissive_matrix = permissive_matrix_raw.iloc[:,3:-1]\n",
    "# Invert -1 and 0 (0 should be low and -1 unknown)\n",
    "permissive_matrix.to_numpy()[permissive_matrix_raw.iloc[:,3:-1] == -1] = 0\n",
    "permissive_matrix.to_numpy()[permissive_matrix_raw.iloc[:,3:-1] == 0] = -1\n",
    "permissive_matrix.to_csv(os.path.join(preprocessing_python_dir, 'ssort_prior_permissive.csv'),\n",
    "                         index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a terminal, with the `/data/preprocessing/annotations` at the root folder and a Python environment with SpatialSort installed:\n",
    "```bash\n",
    "mkdir ssort\n",
    "SpatialSort infer --exp-csv 'ssort_expression.csv' --loc-csv 'ssort_location.csv' --rel-csv 'ssort_relation.csv' -k 20 -s 2 -t 1000 -o \"ssort/\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
