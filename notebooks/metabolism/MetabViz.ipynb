{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore metabolism of cancer cells\n",
    "Corresponds to fig 3 and sfig 3 in draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad('../../data/adata_consensus_cell_types.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functional_and_metab = ['CA9', 'CD98', 'CytC', 'MSH2', 'MCT1', 'ASCT2',\n",
    "       'LDH', 'STING1', 'GS', 'GLS', 'ATP5A', 'CS', 'PKM2', 'GLUT1', 'MSH6', 'ARG1', 'CPT1A', 'Ki67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rows by cell type and compute median expression\n",
    "df = adata.obs.loc[:,all_functional_and_metab]\n",
    "df[\"cell_type\"] = adata.obs[\"annotation_consensus\"].values\n",
    "df = df.groupby(\"cell_type\").median().T\n",
    "df = df.drop(\"Unclear\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "# Perform hierarchical clustering\n",
    "row_linkage = linkage(df, method='complete')\n",
    "col_linkage = linkage(df.T, method='complete')\n",
    "\n",
    "# Get the order of rows and columns\n",
    "row_order = leaves_list(row_linkage)\n",
    "col_order = leaves_list(col_linkage)\n",
    "\n",
    "# Scale df values so that each row (abundance for a given marker) is between 0 and 1\n",
    "df = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)), axis = 1)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df_reordered = df.iloc[row_order, :].iloc[:, col_order]\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df_reordered = df.iloc[row_order, :].iloc[:, col_order]\n",
    "\n",
    "# Melt the DataFrame for plotnine\n",
    "df_melted = df_reordered.melt(ignore_index=False).reset_index()\n",
    "\n",
    "# Update the levels of the categorical variables to reflect the new order\n",
    "df_melted[\"index\"] = pd.Categorical(df_melted[\"index\"], categories=df_reordered.index, ordered=True)\n",
    "df_melted[\"cell_type\"] = pd.Categorical(df_melted[\"cell_type\"], categories=df_reordered.columns.to_list(), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as heatmap\n",
    "gp = (\n",
    "    ggplot(df_melted, aes(x=\"index\", y=\"cell_type\")) \n",
    "    + geom_tile(aes(fill=\"value\")) \n",
    "    + theme_classic() \n",
    "    + theme(axis_text_x=element_text(angle=90)) \n",
    "    + labs(y=\"Cell type\", x=\"Marker\", fill=\"Median\\nabundance\") \n",
    "    # + coord_equal()\n",
    "    # Use reverted plasma color palette\n",
    "    + scale_fill_gradientn(colors = [\"#EFF822\", \"#CC4977\",\"#0F0782\"])\n",
    ")\n",
    "ggsave(gp, \"../../figures/fig3/heatmap_all_markers_scaled.png\", width = 6, height = 3.2)\n",
    "ggsave(gp, \"../../figures/fig3/heatmap_all_markers_scaled.pdf\", width = 6, height = 3.2)\n",
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the analysis for each tumor stage\n",
    "clini = pd.read_csv(\"../../data/summary_clinical_data_modified.csv\", index_col=2)\n",
    "adata.obs = adata.obs.merge(clini, left_on=\"fov\", right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Stage\"] = adata.obs[\"pT group\"]\n",
    "# # E1 and E2 samples are annotated 'SCT' while E3 and E4 are 'Colon-no.'\n",
    "adata.obs.loc[adata.obs.fov.str.contains(\"E4\"), \"Stage\"] = \"Colon-no.\"\n",
    "adata.obs.loc[adata.obs.fov.str.contains(\"E3\"), \"Stage\"] = \"Colon-no.\"\n",
    "adata.obs.loc[adata.obs.fov.str.contains(\"E2\"), \"Stage\"] = \"SCT\"\n",
    "adata.obs.loc[adata.obs.fov.str.contains(\"E1\"), \"Stage\"] = \"SCT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for later spatial analyses\n",
    "adata.obs.to_csv(\"../../data/cell_table_with_types_stage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in adata.obs['Stage'].unique():\n",
    "    if pd.isna(stage):\n",
    "        continue\n",
    "\n",
    "    df = adata.obs.loc[adata.obs['Stage'] == stage, all_functional_and_metab]\n",
    "    df[\"cell_type\"] = adata.obs.loc[adata.obs['Stage'] == stage, \"annotation_consensus\"].values\n",
    "    df = df.groupby(\"cell_type\").median().T\n",
    "    df = df.drop(\"Unclear\", axis=1)\n",
    "\n",
    "    # We keep the order of the markers and cell types from the previous analysis for consistency\n",
    "\n",
    "    # Scale df values so that each row (abundance for a given marker) is between 0 and 1\n",
    "    df = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)), axis = 1)\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df_reordered = df.iloc[row_order, :].iloc[:, col_order]\n",
    "\n",
    "    # Melt the DataFrame for plotnine\n",
    "    df_melted = df_reordered.melt(ignore_index=False).reset_index()\n",
    "\n",
    "    # Update the levels of the categorical variables to reflect the new order\n",
    "    df_melted[\"index\"] = pd.Categorical(df_melted[\"index\"], categories=df_reordered.index, ordered=True)\n",
    "    df_melted[\"cell_type\"] = pd.Categorical(df_melted[\"cell_type\"], categories=df_reordered.columns.to_list(), ordered=True)\n",
    "\n",
    "    # Display as heatmap\n",
    "    gp = (\n",
    "        ggplot(df_melted, aes(x=\"index\", y=\"cell_type\")) \n",
    "        + geom_tile(aes(fill=\"value\")) \n",
    "        + theme_classic() \n",
    "        + theme(axis_text_x=element_text(angle=90)) \n",
    "        + labs(y=\"Cell type\", x=\"Marker\", fill=\"Median\\nabundance\") \n",
    "        # Use reverted plasma color palette\n",
    "        + scale_fill_gradientn(colors = [\"#EFF822\", \"#CC4977\",\"#0F0782\"])\n",
    "        + ggtitle(f\"Stage {stage}\")\n",
    "    )\n",
    "    print(gp)\n",
    "    ggsave(gp, f\"../../figures/fig3/heatmap_all_markers_scaled_stage_{stage}.png\", width = 6, height = 3.2)\n",
    "    ggsave(gp, f\"../../figures/fig3/heatmap_all_markers_scaled_stage_{stage}.pdf\", width = 6, height = 3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLUT1 high in neutrophils and cancer cells â€“ not in healthy epithelial cells. Also higher proliferation (Ki67). Also CD98 (neutral aa transporter) high, MSH6 / MSH2 / LDH low in cancer vs epithelial.  \n",
    "Caveat: scaled scores are computed per marker per stage and not across stages. Scaling values before computing the median means giving weight to outliers (if using min and max) or doing what's done already (if using small/large percentiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancer cell metab subgroups\n",
    "Leiden on metabolic markers only? Enrichment by pathway then cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 0: metabolic marker intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",[\"LDH\", \"GLUT1\",'pT group']] \n",
    "df[\"Stage\"] = df[\"pT group\"].replace({pd.NA: \"pT0\"})\n",
    "gp = (ggplot(df, aes(x=\"LDH\", y=\"GLUT1\", color='Stage')) \n",
    "      + geom_point(alpha = 0.1) + theme_classic() + facet_wrap(\"~Stage\")\n",
    ")\n",
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",[\"CD98\", \"Ki67\",'pT group']] \n",
    "df[\"Stage\"] = df[\"pT group\"].replace({pd.NA: \"pT0\"})\n",
    "gp = (ggplot(df, aes(x=\"CD98\", y=\"Ki67\", color='Stage')) \n",
    "      + geom_point(alpha = 0.1) + theme_classic() + facet_wrap(\"~Stage\")\n",
    ")\n",
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs.loc[adata.obs.fov == \"A1c\",adata.obs.columns[:23]]\n",
    "df[\"cell_type\"] = adata.obs.loc[adata.obs.fov == \"A1c\", \"annotation_consensus\"].values\n",
    "df = df.groupby(\"cell_type\").median().T\n",
    "df = df.drop(\"Unclear\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs.loc[adata.obs.fov == \"E4a\",adata.obs.columns[:23]]\n",
    "df[\"cell_type\"] = adata.obs.loc[adata.obs.fov == \"E4a\", \"annotation_consensus\"].values\n",
    "df = df.groupby(\"cell_type\").median().T\n",
    "df = df.drop(\"Unclear\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(adata.X[adata.obs.fov == \"E4a\",:], columns=adata.var_names)\n",
    "df[\"cell_type\"] = adata.obs.loc[adata.obs.fov == \"E4a\", \"annotation_consensus\"].values\n",
    "df = df.groupby(\"cell_type\").median().T\n",
    "df = df.drop(\"Unclear\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",[\"LDH\", \"GLUT1\",'pT group','fov']] \n",
    "df[\"Stage\"] = df[\"pT group\"]\n",
    "# # E1 and E2 samples are annotated 'SCT' while E3 and E4 are 'Colon-no.'\n",
    "df.loc[df.fov.str.contains(\"E4\"), \"Stage\"] = \"Colon-no.\"\n",
    "df.loc[df.fov.str.contains(\"E3\"), \"Stage\"] = \"Colon-no.\"\n",
    "df.loc[df.fov.str.contains(\"E2\"), \"Stage\"] = \"SCT\"\n",
    "df.loc[df.fov.str.contains(\"E1\"), \"Stage\"] = \"SCT\"\n",
    "\n",
    "gp = (ggplot(df, aes(x=\"LDH\", y=\"GLUT1\", color='Stage')) \n",
    "      + geom_point(alpha = 0.1) + theme_classic() + facet_wrap(\"~Stage\")\n",
    ")\n",
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",[\"CD98\", \"Ki67\",'pT group','fov']] \n",
    "df[\"Stage\"] = df[\"pT group\"]\n",
    "# # E1 and E2 samples are annotated 'SCT' while E3 and E4 are 'Colon-no.'\n",
    "df.loc[df.fov.str.contains(\"E4\"), \"Stage\"] = \"Colon-no.\"\n",
    "df.loc[df.fov.str.contains(\"E3\"), \"Stage\"] = \"Colon-no.\"\n",
    "df.loc[df.fov.str.contains(\"E2\"), \"Stage\"] = \"SCT\"\n",
    "df.loc[df.fov.str.contains(\"E1\"), \"Stage\"] = \"SCT\"\n",
    "\n",
    "gp = (ggplot(df, aes(x=\"CD98\", y=\"Ki67\", color='Stage')) \n",
    "      + geom_point(alpha = 0.1) + theme_classic() + facet_wrap(\"~Stage\")\n",
    ")\n",
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in adata.obs['pT group'].unique():\n",
    "    if pd.isna(stage):\n",
    "        df = adata.obs.loc[adata.obs['pT group'].isna(), all_functional_and_metab]\n",
    "        df[\"cell_type\"] = adata.obs.loc[adata.obs['pT group'].isna(), \"annotation_consensus\"].values\n",
    "    else:\n",
    "        df = adata.obs.loc[adata.obs['pT group'] == stage, all_functional_and_metab]\n",
    "        df[\"cell_type\"] = adata.obs.loc[adata.obs['pT group'] == stage, \"annotation_consensus\"].values\n",
    "    df = df.groupby(\"cell_type\").median().T\n",
    "    df = df.drop(\"Unclear\", axis=1)\n",
    "\n",
    "    # We keep the order of the markers and cell types from the previous analysis for consistency\n",
    "\n",
    "    # Scale df values so that each row (abundance for a given marker) is between 0 and 1\n",
    "    df = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)), axis = 1)\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df_reordered = df.iloc[row_order, :].iloc[:, col_order]\n",
    "\n",
    "    # Melt the DataFrame for plotnine\n",
    "    df_melted = df_reordered.melt(ignore_index=False).reset_index()\n",
    "\n",
    "    # Update the levels of the categorical variables to reflect the new order\n",
    "    df_melted[\"index\"] = pd.Categorical(df_melted[\"index\"], categories=df_reordered.index, ordered=True)\n",
    "    df_melted[\"cell_type\"] = pd.Categorical(df_melted[\"cell_type\"], categories=df_reordered.columns.to_list(), ordered=True)\n",
    "\n",
    "    # Display as heatmap\n",
    "    gp = (\n",
    "        ggplot(df_melted, aes(x=\"index\", y=\"cell_type\")) \n",
    "        + geom_tile(aes(fill=\"value\")) \n",
    "        + theme_classic() \n",
    "        + theme(axis_text_x=element_text(angle=90)) \n",
    "        + labs(y=\"Cell type\", x=\"Marker\", fill=\"Median\\nabundance\") \n",
    "        # Use reverted plasma color palette\n",
    "        + scale_fill_gradientn(colors = [\"#EFF822\", \"#CC4977\",\"#0F0782\"])\n",
    "        + ggtitle(f\"Stage {stage}\")\n",
    "    )\n",
    "    print(gp)\n",
    "    # ggsave(gp, f\"figures/fig3/heatmap_all_markers_scaled_stage_{stage}.png\", width = 6, height = 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancer cell metabolism\n",
    "In this section, we explore the variations in metabolic activitiy of epithelial / malignant cells, and how it evolves with the disease stage.  \n",
    "For now, we ignore the influence of other cell types, and start by looking at ...  \n",
    "While a classification at the cell level shows the informativeness of individual cell metabolic profiles, not all cells have to be representative of the disease as a whole. The most relevant representation should thus be the one best representing FOVs/samples. For given markers, the aggregation can be attempted as follows: no aggregation, mean profile (train on cells or on mean profiles), median profile (train on cells on or median profiles), clustering and proportions. We want to compare these methods (and ideally later use the same split for multicellular / spatial analyses) -> 4xCV + validation set (per FOV) = 1 healthy donor per fold.  \n",
    "How does it relate to proliferation/aggressiveness?  \n",
    "QC: cosine similarity between cells from the same stage?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 1: keep all markers separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_markers = ['CA9', 'CD98', 'CytC', 'MCT1', 'ASCT2', 'LDH', 'GS', 'GLS', 'ATP5A', 'CS', 'PKM2', 'GLUT1', 'ARG1', 'CPT1A', 'Ki67']\n",
    "\n",
    "# Only metabolic markers for cancer/epithelial cells\n",
    "df = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",metab_markers] \n",
    "meta = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",[\"Stage\",\"fov\"]]\n",
    "\n",
    "# Only keep well-annotated stages\n",
    "epithelial_subset = meta[\"Stage\"].isin([\"Colon-no.\", \"pT1\", \"pT2\", \"pT3\", \"pT4\"]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization:\n",
    "```python\n",
    "import umap\n",
    "\n",
    "# Reduce to 2 dimensions with UMAP\n",
    "umap_metab = umap.UMAP(random_state=42).fit_transform(df)\n",
    "\n",
    "umap_metab = pd.DataFrame(umap_metab, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "umap_metab[\"stage\"] = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\",'Stage'].values\n",
    "\n",
    "gp = (ggplot(umap_metab, aes(x=\"UMAP1\", y=\"UMAP2\", color=\"stage\")) \n",
    "      + geom_point() + theme_classic()\n",
    ")\n",
    "gp\n",
    "\n",
    "gp = (ggplot(umap_metab, aes(x=\"UMAP1\", y=\"UMAP2\")) \n",
    "      + geom_bin2d() + theme_classic()\n",
    "      + facet_wrap(\"~stage\")\n",
    ")\n",
    "gp \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which fovs will be held out for validation (outer loop)\n",
    "fov_stage_table = meta.loc[epithelial_subset].drop_duplicates().reset_index(drop=True)\n",
    "fov_inner, fov_val, y_inner, y_val = train_test_split(\n",
    "    fov_stage_table[\"fov\"], fov_stage_table[\"Stage\"], test_size=0.2, random_state=0, stratify=fov_stage_table[\"Stage\"])\n",
    "meta[\"inner\"] = meta[\"fov\"].isin(fov_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "\n",
    "cv_folds = StratifiedGroupKFold(n_splits=n_splits)\n",
    "for train, test in cv_folds.split(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "                                  meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "                                  groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]):\n",
    "    # All stages should be present in both train and test\n",
    "    assert len(meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[test].groupby(\"fov\")[\"Stage\"].first().unique()) == 5\n",
    "    assert len(meta.loc[epithelial_subset].loc[meta[\"inner\"]].iloc[train].groupby(\"fov\")[\"Stage\"].first().unique()) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_fov = df.copy()\n",
    "df_per_fov[\"fov\"] = meta[\"fov\"] \n",
    "df_per_fov = df_per_fov.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].groupby(\"fov\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on FOV mean, test on FOV mean\n",
    "cv_folds_fov = StratifiedKFold(n_splits=n_splits)\n",
    "for train, test in cv_folds_fov.split(df_per_fov,\n",
    "                                  meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"]\n",
    "                                  ):\n",
    "    print(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first().iloc[test][\"Stage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df_per_fov,\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"]),\n",
    "    cv=cv_folds_fov, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in cv_folds.split(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "                                  meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "                                  groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]):\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0)\n",
    "    xgb.fit(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train],\n",
    "            LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[train]))\n",
    "    # First show f1_score on test data\n",
    "    preds = xgb.predict(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test])\n",
    "    print(f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[test]), \n",
    "                   preds, \n",
    "                   average=\"macro\"))\n",
    "    # This recapitulates the results of calling `cross_val_score`\n",
    "\n",
    "    # Train on individual cells, test on FOV mean\n",
    "    test_fov = meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"].iloc[test].unique()\n",
    "    preds = xgb.predict(df_per_fov.loc[test_fov])\n",
    "    print(f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[test_fov]), \n",
    "                   preds, \n",
    "                   average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with median instead of mean\n",
    "df_per_fov = df.copy()\n",
    "df_per_fov[\"fov\"] = meta[\"fov\"] \n",
    "df_per_fov = df_per_fov.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].groupby(\"fov\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df_per_fov,\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"]),\n",
    "    cv=cv_folds_fov, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in cv_folds.split(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "                                  meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "                                  groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]):\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0)\n",
    "    xgb.fit(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train],\n",
    "            LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[train]))\n",
    "    # First show f1_score on test data\n",
    "    preds = xgb.predict(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test])\n",
    "    print(f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"].iloc[test]), \n",
    "                   preds, \n",
    "                   average=\"macro\"))\n",
    "    # This recapitulates the results of calling `cross_val_score`\n",
    "\n",
    "    # Train on individual cells, test on FOV median\n",
    "    test_fov = meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"].iloc[test].unique()\n",
    "    preds = xgb.predict(df_per_fov.loc[test_fov])\n",
    "    print(f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[test_fov]), \n",
    "                   preds, \n",
    "                   average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ind\n",
    "(0.21334178256892686 + 0.3047374279671758 + 0.29207851933589885 + 0.2485800697783061)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Med\n",
    "np.mean([0.20805219, 0.19189579, 0.21131957, 0.1926093 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ind + Mean pred\n",
    "(0.18001782001782002+0.4324540247211335+0.36690958164642373+0.16494823006450915)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ind + Median pred\n",
    "(0.16813147914032872 + 0.3699462365591398 + 0.3417610522469857 + 0.18623318819545237)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on what methods are kept\n",
    "# from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scanpy as sc\n",
    "from joblib import Parallel, delayed\n",
    "import warnings, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(train, test, n_neighbors = 30, resolution = 0.5, n_estimators = 250):\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        # Step 1: Define metabolic clusters on training data\n",
    "        ad = sc.AnnData(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train])\n",
    "        sc.pp.neighbors(ad, n_neighbors=n_neighbors)\n",
    "        sc.tl.leiden(ad, resolution=resolution)\n",
    "        ad.obs.leiden = ad.obs.leiden.values.astype(int)\n",
    "\n",
    "        # Step 2: Define a classifier to propagate the clusters to the test data\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "        neigh.fit(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train].values, \n",
    "                ad.obs.leiden.values)\n",
    "\n",
    "        # Step 3: Compute proportion of cells in each cluster for each FOV in the training data\n",
    "        train_fov_cluster_composition = pd.DataFrame(ad.obs.leiden.values, columns=[\"Cluster\"])\n",
    "        train_fov_cluster_composition[\"fov\"] = (\n",
    "            meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train][\"fov\"].values\n",
    "        )\n",
    "        train_fov_cluster_composition = (\n",
    "            train_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    "        )\n",
    "        # Normalize by the number of cells in each FOV\n",
    "        train_fov_cluster_composition = (\n",
    "            train_fov_cluster_composition.div(train_fov_cluster_composition.sum(axis=1), axis=0)\n",
    "        )\n",
    "\n",
    "        # Step 4: Train a classifier on the training data composition to predict the stage of each FOV\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=3, \n",
    "            device=\"cuda\", \n",
    "            random_state=0)\n",
    "        xgb.fit(train_fov_cluster_composition,\n",
    "                LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[train_fov_cluster_composition.index]))\n",
    "        \n",
    "        # Step 5: Predict clusters on test data\n",
    "        test_clusters = neigh.predict(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test].values)\n",
    "\n",
    "        # Step 6: Compute proportion of cells in each cluster for each FOV in the test data\n",
    "        test_fov_cluster_composition = pd.DataFrame(test_clusters, columns=[\"Cluster\"])\n",
    "        test_fov_cluster_composition[\"fov\"] = meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test][\"fov\"].values\n",
    "        test_fov_cluster_composition = test_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    "        # Normalize by the number of cells in each FOV\n",
    "        test_fov_cluster_composition = test_fov_cluster_composition.div(test_fov_cluster_composition.sum(axis=1), axis=0)\n",
    "        \n",
    "        # Ensure all clusters are covered in the testing dataframe\n",
    "        for cluster in train_fov_cluster_composition.columns:\n",
    "            if cluster not in test_fov_cluster_composition.columns:\n",
    "                test_fov_cluster_composition[cluster] = 0\n",
    "\n",
    "        # Reorder columns to match the training set\n",
    "        test_fov_cluster_composition = test_fov_cluster_composition[train_fov_cluster_composition.columns]\n",
    "\n",
    "        # Step 7: Predict stage of each FOV in the test data\n",
    "        preds = xgb.predict(test_fov_cluster_composition)\n",
    "\n",
    "        # Step 8: Compute f1_score\n",
    "        score = f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[test_fov_cluster_composition.index]), \n",
    "                        preds, \n",
    "                        average=\"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single set of hyperparameters\n",
    "def process_hyperparameters(r_resolution, r_neighbors, r_estimators):\n",
    "    r_neighbors = int(r_neighbors)\n",
    "    print(r_resolution, r_neighbors, r_estimators)\n",
    "    scores = Parallel(n_jobs=1)(delayed(process_fold)(train, \n",
    "                                                       test, \n",
    "                                                       n_neighbors=r_neighbors,\n",
    "                                                       resolution=r_resolution,\n",
    "                                                       n_estimators=r_estimators) \n",
    "                                 for train, test in cv_folds.split(\n",
    "        df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    ))\n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"[Results]  \", r_resolution, r_neighbors, r_estimators, mean_score)\n",
    "    \n",
    "    # Ensure file exists\n",
    "    if not os.path.isfile(\"../../data/cluster_f1_scores.txt\"):\n",
    "        with open(\"../../data/cluster_f1_scores.txt\", \"w\") as f:\n",
    "            f.write(\"resolution,neighbors,estimators,score\\n\")\n",
    "\n",
    "    # Append to f1 score log file\n",
    "    with open(f\"../../data/cluster_f1_scores.txt\", \"a\") as f:\n",
    "        f.write(f\"{r_resolution},{r_neighbors},{r_estimators},{mean_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# Perform nb_sim tests for random values of n_neighbors, RF estimators and Leiden resolution\n",
    "nb_sim = 10\n",
    "np.random.seed(1)\n",
    "resolutions = np.round(np.random.rand(nb_sim), 2)\n",
    "neighbors = np.ceil(100 * np.random.pareto(6, nb_sim))\n",
    "estimators = np.random.randint(500, size=nb_sim)\n",
    "\n",
    "# Parallelize the hyperparameter loop\n",
    "Parallel(n_jobs=28)(delayed(process_hyperparameters)(r_resolution, r_neighbors, r_estimators)\n",
    "                for r_resolution, r_neighbors, r_estimators in zip(resolutions, neighbors, estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../../data/cluster_f1_scores.txt\").sort_values(\"score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterize best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.69\n",
    "neighbors = 31\n",
    "estimators = 226"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Parallel(n_jobs=-1)(delayed(process_fold)(train, \n",
    "                                                       test, \n",
    "                                                       n_neighbors=neighbors,\n",
    "                                                       resolution=res,\n",
    "                                                       n_estimators=estimators) \n",
    "                                 for train, test in cv_folds.split(\n",
    "        df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "        meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "        groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]\n",
    "    )) # This should confirm the model selection estimates\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we selected the model hyperparameters, retrain it on the full inner CV dataset and characterize it\n",
    "# Step 1: Define metabolic clusters on training data\n",
    "ad = sc.AnnData(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]])\n",
    "sc.pp.neighbors(ad, n_neighbors=neighbors)\n",
    "sc.tl.leiden(ad, resolution=res)\n",
    "ad.obs.leiden = ad.obs.leiden.values.astype(int)\n",
    "\n",
    "# Step 2: Define a classifier to propagate the clusters to the validation data\n",
    "neigh = KNeighborsClassifier(n_neighbors=neighbors, n_jobs=-1)\n",
    "neigh.fit(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].values, \n",
    "        ad.obs.leiden.values)\n",
    "\n",
    "# Step 3: Compute proportion of cells in each cluster for each FOV in the training data\n",
    "train_fov_cluster_composition = pd.DataFrame(ad.obs.leiden.values, columns=[\"Cluster\"])\n",
    "train_fov_cluster_composition[\"fov\"] = (\n",
    "    meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]][\"fov\"].values\n",
    ")\n",
    "train_fov_cluster_composition = (\n",
    "    train_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    ")\n",
    "# Normalize by the number of cells in each FOV\n",
    "train_fov_cluster_composition = (\n",
    "    train_fov_cluster_composition.div(train_fov_cluster_composition.sum(axis=1), axis=0)\n",
    ")\n",
    "\n",
    "# Step 4: Train a classifier on the training data composition to predict the stage of each FOV\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=estimators, \n",
    "    max_depth=3, \n",
    "    device=\"cuda\", \n",
    "    random_state=0)\n",
    "xgb.fit(train_fov_cluster_composition,\n",
    "        LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[train_fov_cluster_composition.index]))\n",
    "\n",
    "print(\"Number of metabolic clusters:\", len(train_fov_cluster_composition.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "explainer = shap.Explainer(xgb)\n",
    "shap_values = explainer(train_fov_cluster_composition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The Shapley value is the average contribution of a feature value to the prediction in different coalitions. The Shapley value is NOT the difference in prediction when we would remove the feature from the model.\n",
    "```\n",
    "Note: it could be more appropriate to use a custom `explainer` to rely on marginal distributions rather than conditional distributions (default for xgboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purples + Green for healthy\n",
    "pal_stages = [(127,201,127), (242,240,247), (203,201,226), (158,154,201), (106,81,163)]\n",
    "# Convert to hex\n",
    "pal_stages = ['#%02x%02x%02x' % (r, g, b) for r, g, b in pal_stages]\n",
    "\n",
    "original_stages = meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[train_fov_cluster_composition.index]\n",
    "label_encoder = LabelEncoder()\n",
    "true_labels = label_encoder.fit_transform(original_stages)\n",
    "predicted_labels = xgb.predict(train_fov_cluster_composition)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(conf_matrix)\n",
    "# Few errors on training set, so not meaningful to interpret misclassified FOVs\n",
    "\n",
    "# For each stage, see how the true positive samples were predicted (SHAP values)\n",
    "\n",
    "# Get indices of correctly predicted samples for each class\n",
    "correct_indices = {class_idx: np.where((true_labels == class_idx) & (predicted_labels == class_idx))[0] \n",
    "                   for class_idx in range(conf_matrix.shape[0])}\n",
    "\n",
    "shap_values_list = []\n",
    "for class_idx, indices in correct_indices.items():\n",
    "    shap_values_class = pd.DataFrame(shap_values.values[indices, :, class_idx], columns=train_fov_cluster_composition.columns)\n",
    "    shap_values_class['fov'] = train_fov_cluster_composition.index[indices]\n",
    "    shap_values_class['class'] = label_encoder.inverse_transform([class_idx])[0]  # Use original stage names\n",
    "    shap_values_list.append(shap_values_class)\n",
    "\n",
    "shap_values_df = pd.concat(shap_values_list)\n",
    "\n",
    "# Melt the DataFrame for easier plotting with plotnine\n",
    "shap_values_melted = shap_values_df.melt(id_vars=['fov', 'class'], var_name='Feature', value_name='SHAP Value')\n",
    "\n",
    "# Compute mean and std SHAP values for feature importance for each class\n",
    "feature_importance = shap_values_melted.groupby(['class', 'Feature'])['SHAP Value'].agg(['mean', 'std']).reset_index()\n",
    "# We want to display either high positive or high negative values\n",
    "feature_importance[\"abs_mean\"] = np.abs(feature_importance[\"mean\"]) \n",
    "feature_importance = feature_importance.sort_values(by=['class', 'abs_mean'], ascending=[True, False])\n",
    "feature_importance = feature_importance.loc[feature_importance.Feature.isin(feature_importance.groupby('class').head(2).Feature)]\n",
    "\n",
    "# Add a column for reordering features\n",
    "feature_importance['Feature'] = pd.Categorical(feature_importance['Feature'], \n",
    "                                               categories=feature_importance.groupby('class').head(2).Feature.unique()[::-1], \n",
    "                                               ordered=True)\n",
    "feature_importance['class'] = feature_importance['class'].astype('category')\n",
    "\n",
    "# Step 8: Visualize feature importance using plotnine\n",
    "p2 = (ggplot(feature_importance, \n",
    "                aes(x='Feature', y='mean', fill='class'))\n",
    "      + geom_bar(stat='identity', position='dodge')\n",
    "      + geom_errorbar(aes(ymin='mean-std', ymax='mean+std'), width=0.2, position='dodge')\n",
    "      + coord_flip()\n",
    "      + theme_classic()\n",
    "      + scale_fill_manual(values=pal_stages)\n",
    "      + labs(title='Feature importance by stage (correctly predicted samples)', x='Metabolic cluster', y='Mean SHAP value', fill='Stage')\n",
    "      + facet_wrap('~class', scales='free_y'))\n",
    "\n",
    "ggsave(p2, \"../../figures/fig3/feature_importance_correctly_predicted_samples.pdf\", width=7, height=5)\n",
    "\n",
    "p2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret individual clusters\n",
    "How frequent? What composition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fov_cluster_composition[\"Stage\"] = \"Misclassified\"\n",
    "for k,v in correct_indices.items():\n",
    "    train_fov_cluster_composition.loc[\n",
    "        train_fov_cluster_composition.index[v], \n",
    "        \"Stage\"] = label_encoder.inverse_transform([k])[0]\n",
    "    \n",
    "for clust in feature_importance.Feature.cat.categories:\n",
    "    print(clust)\n",
    "    # How frequent is this cluster?\n",
    "    print(train_fov_cluster_composition[clust].mean())\n",
    "\n",
    "# Step 1: Compute the average frequency of each cluster for each stage\n",
    "average_frequency = train_fov_cluster_composition.groupby(\"Stage\").mean().reset_index()\n",
    "\n",
    "# Melt the DataFrame for easier plotting with plotnine\n",
    "average_frequency_melted = average_frequency.melt(id_vars=['Stage'], var_name='Cluster', value_name='Frequency')\n",
    "average_frequency_melted = average_frequency_melted.loc[average_frequency_melted.Stage != \"Misclassified\"]\n",
    "average_frequency_melted = average_frequency_melted.loc[average_frequency_melted[\"Cluster\"].isin(feature_importance.Feature.cat.categories)]\n",
    "\n",
    "# Step 2: Prepare the data for plotting\n",
    "# Ensure that the 'Stage' column is treated as a categorical variable\n",
    "average_frequency_melted['Stage'] = pd.Categorical(average_frequency_melted['Stage'], \n",
    "                                                   categories=average_frequency_melted['Stage'].unique(), \n",
    "                                                   ordered=True)\n",
    "average_frequency_melted['Cluster'] = pd.Categorical(average_frequency_melted['Cluster'], \n",
    "                                                     categories=feature_importance.Feature.cat.categories, \n",
    "                                                     ordered=True)\n",
    "\n",
    "# Step 3: Create the dot plot using plotnine\n",
    "p = (ggplot(average_frequency_melted, aes(x='Cluster', y='Stage', size='Frequency'))\n",
    "     + geom_point()\n",
    "     + theme_classic()\n",
    "     + coord_flip()\n",
    "     + scale_size_continuous(range=[2, 15])\n",
    "     + labs(title='Average frequency of clusters by sample', x='Cluster', y='Stage', size='Average frequency'))\n",
    "\n",
    "ggsave(p, \"../../figures/fig3/average_frequency_clusters_by_stage.pdf\", width=7, height=5)\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter the Data\n",
    "shortlisted_features = feature_importance.Feature.cat.categories\n",
    "shortlisted_indices = ad.obs.leiden.isin(shortlisted_features)\n",
    "\n",
    "# Step 2: Group by Cluster\n",
    "# Create a DataFrame with marker expression and cluster information\n",
    "marker_expression = pd.DataFrame(ad.X[shortlisted_indices, :], columns=ad.var_names)\n",
    "marker_expression['Cluster'] = ad.obs['leiden'].loc[shortlisted_indices].values\n",
    "\n",
    "# Group by cluster and compute the mean expression for each marker\n",
    "grouped_expression = marker_expression.groupby('Cluster').mean()\n",
    "\n",
    "# Step 3: Cluster the Result\n",
    "# Perform hierarchical clustering on the grouped data\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "row_linkage = linkage(grouped_expression, method='complete')\n",
    "col_linkage = linkage(grouped_expression.T, method='complete')\n",
    "\n",
    "# Get the order of rows and columns\n",
    "row_order = leaves_list(row_linkage)\n",
    "col_order = leaves_list(col_linkage)\n",
    "\n",
    "# Scale df values so that each column (abundance for a given marker) is between 0 and 1\n",
    "grouped_expression = grouped_expression.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)), axis = 0)\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df_reordered = grouped_expression.iloc[row_order, :].iloc[:, col_order]\n",
    "\n",
    "# Melt the DataFrame for plotnine\n",
    "df_melted = df_reordered.melt(ignore_index=False).reset_index()\n",
    "\n",
    "# Update the levels of the categorical variables to reflect the new order\n",
    "df_melted[\"Cluster\"] = pd.Categorical(df_melted[\"Cluster\"], categories=df_reordered.index, ordered=True)\n",
    "df_melted[\"variable\"] = pd.Categorical(df_melted[\"variable\"], categories=df_reordered.columns.to_list(), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as heatmap\n",
    "gp = (\n",
    "    ggplot(df_melted, aes(x=\"variable\", y=\"Cluster\")) \n",
    "    + geom_tile(aes(fill=\"value\")) \n",
    "    + theme_classic() \n",
    "    + theme(axis_text_x=element_text(angle=90)) \n",
    "    + labs(y=\"Epithelial cluster\", x=\"Marker\", fill=\"Median\\nabundance\") \n",
    "    # Use reverted plasma color palette\n",
    "    + scale_fill_gradientn(colors = [\"#EFF822\", \"#CC4977\",\"#0F0782\"])\n",
    ")\n",
    "print(gp)\n",
    "ggsave(gp, f\"../../figures/fig3/heatmap_metab_markers_clusters.png\", width = 6, height = 3.2)\n",
    "ggsave(gp, f\"../../figures/fig3/heatmap_metab_markers_clusters.pdf\", width = 6, height = 3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.cluster import HDBSCAN\n",
    "\n",
    "hdb = HDBSCAN(min_cluster_size = 25)\n",
    "hdb.fit(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train].values)\n",
    "pd.Series(hdb.labels_).value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: maybe the computation could be made faster if the KNN classifier used the precomputed NN from scanpy? In practice it is not faster (as scanpy's distance computation is slower than scipy's).\n",
    "```python\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "for train, test in cv_folds.split(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "                                  meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"],\n",
    "                                  groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"]):\n",
    "    n_neighbors = 30\n",
    "\n",
    "    # Step 1: Define metabolic clusters on training data\n",
    "    ad = sc.AnnData(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train])\n",
    "    sc.pp.neighbors(ad, n_neighbors=n_neighbors)\n",
    "    sc.tl.leiden(ad, resolution=0.5)\n",
    "    ad.obs.leiden = ad.obs.leiden.values.astype(int)\n",
    "\n",
    "    # Step 2: Define a classifier to propagate the clusters to the test data\n",
    "    neighbors_graph = ad.obsp['connectivities'] # Extract nn graph\n",
    "    neighbors_graph = sort_graph_by_row_values(neighbors_graph)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric = 'precomputed')\n",
    "    neigh.fit(neighbors_graph, \n",
    "              ad.obs.leiden.values)\n",
    "\n",
    "    # Step 3: Compute proportion of cells in each cluster for each FOV in the training data\n",
    "    train_fov_cluster_composition = pd.DataFrame(ad.obs.leiden.values, columns=[\"Cluster\"])\n",
    "    train_fov_cluster_composition[\"fov\"] = (\n",
    "        meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train][\"fov\"].values\n",
    "    )\n",
    "    train_fov_cluster_composition = (\n",
    "        train_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    "    )\n",
    "    # Normalize by the number of cells in each FOV\n",
    "    train_fov_cluster_composition = (\n",
    "        train_fov_cluster_composition.div(train_fov_cluster_composition.sum(axis=1), axis=0)\n",
    "    )\n",
    "\n",
    "    # Step 4: Train a classifier on the training data composition to predict the stage of each FOV\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0)\n",
    "    xgb.fit(train_fov_cluster_composition,\n",
    "            LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[train_fov_cluster_composition.index]))\n",
    "    \n",
    "    # Step 5: Predict clusters on test data\n",
    "    test_distances = distance_matrix(df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test].values,\n",
    "                                     df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[train].values)\n",
    "    test_clusters = neigh.predict(test_distances)\n",
    "    \n",
    "    # Step 6: Compute proportion of cells in each cluster for each FOV in the test data\n",
    "    test_fov_cluster_composition = pd.DataFrame(test_clusters, columns=[\"Cluster\"])\n",
    "    test_fov_cluster_composition[\"fov\"] = meta.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]].iloc[test][\"fov\"].values\n",
    "    test_fov_cluster_composition = test_fov_cluster_composition.groupby(\"fov\")[\"Cluster\"].value_counts().unstack().fillna(0)\n",
    "    # Normalize by the number of cells in each FOV\n",
    "    test_fov_cluster_composition = test_fov_cluster_composition.div(test_fov_cluster_composition.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Ensure all clusters are covered in the testing dataframe\n",
    "    for cluster in train_fov_cluster_composition.columns:\n",
    "        if cluster not in test_fov_cluster_composition.columns:\n",
    "            test_fov_cluster_composition[cluster] = 0\n",
    "\n",
    "    # Reorder columns to match the training set\n",
    "    test_fov_cluster_composition = test_fov_cluster_composition[train_fov_cluster_composition.columns]\n",
    "\n",
    "    # Step 7: Predict stage of each FOV in the test data\n",
    "    preds = xgb.predict(test_fov_cluster_composition)\n",
    "\n",
    "    # Step 8: Compute f1_score\n",
    "    print(f1_score(LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]].groupby(\"fov\").first()[\"Stage\"].loc[test_fov_cluster_composition.index]), \n",
    "                   preds, \n",
    "                   average=\"macro\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 1.1: Less markers\n",
    "Match the marker used to later derive pathway scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_markers = ['CD98', 'CytC', 'MCT1', 'ASCT2', 'LDH', 'GS', 'GLS', 'ATP5A',\n",
    "       'CS', 'PKM2', 'GLUT1']\n",
    "\n",
    "\n",
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"], subset_markers],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 1.2: More markers\n",
    "Use all available measurements, including lineage markers and morphology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(\n",
    "    np.hstack([\n",
    "        adata.obs.loc[adata.obs.consensus == \"Cancer_cell\", adata.obs.columns[:32].drop(['centroid-0','centroid-1'])].values,\n",
    "        adata.X[adata.obs.consensus == \"Cancer_cell\",:]\n",
    "    ]),\n",
    "    columns= adata.obs.columns[:32].drop(['centroid-0','centroid-1']).to_list() + adata.var_names.to_list()\n",
    ")\n",
    "df_all.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df_all.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 2: Unweighted average per main pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pathways = {\n",
    "    \"Glycolysis and Gluconeogenesis\" : [\"MCT1\", \"PKM2\", \"LDH\", \"GLUT1\"],\n",
    "    \"Oxidative phosphorylation\" : [\"ATP5A\", \"CytC\"],\n",
    "    \"TCA cycle\" : [\"CS\", \"MCT1\"],\n",
    "    \"Glutamate metabolism\" : [\"GLS\", \"GS\", \"CD98\", \"ASCT2\"],\n",
    "    \"Valine, Leucine and Isoleucine Metabolism\": [\"ASCT2\", \"MCT1\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(v):\n",
    "    # Get corresponding values and z-score per column\n",
    "    w = df.loc[:,v].apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "    \n",
    "    return np.mean(w, axis = 1)\n",
    "\n",
    "df_metab = pd.DataFrame({k: comp_score(v) for k,v in main_pathways.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df_metab.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 3: Weighted pathway averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_pathways = {\n",
    "    \"Glycolysis and Gluconeogenesis\" : {\"MCT1\":0.2, \"PKM2\": 5, \"LDH\": 1, \"GLUT1\": 0.2},\n",
    "    \"Oxidative phosphorylation\" : {\"ATP5A\": 1, \"CytC\": 1},\n",
    "    \"TCA cycle\" : {\"CS\": 5, \"MCT1\": 0.2},\n",
    "    \"Glutamate metabolism\" : {\"GLS\": 1, \"GS\": 1, \"CD98\": 0.2, \"ASCT2\": 0.2},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(v, k):\n",
    "    # Get corresponding values and z-score per column\n",
    "    w = df.loc[:,v.keys()].apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "    \n",
    "    # Computed weighted mean based on coefficient of each marker\n",
    "    weights = weighted_pathways[k]\n",
    "    w = w.apply(lambda x: x*weights[x.name], axis = 0)\n",
    "    return(np.sum(w, axis = 1)/sum(weights.values()))\n",
    "\n",
    "df_metab2 = pd.DataFrame({k: comp_score(v,k) for k,v in weighted_pathways.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df_metab2.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 4: network diffusion of abundance within pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: get curated pathway membership\n",
    "Curated list obtained from the supplementary material of [Gaude & Frezza (2016)](https://doi.org/10.1038/ncomms13041). Supplementary Data 3 was downloaded and saved in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_pw = pd.read_csv(\"../../data/41467_2016_BFncomms13041_MOESM340_ESM.csv\", header=1)\n",
    "# Rename for consistency\n",
    "main_pathways[\"Citric Acid Cycle\"] = main_pathways[\"TCA cycle\"]\n",
    "main_pathways['Oxidative Phosphorylation'] = main_pathways['Oxidative phosphorylation']\n",
    "# Get the gene symbols for the main pathways\n",
    "all_metab_gene_symbols = curated_pw.loc[curated_pw.Pathways.isin(main_pathways.keys()),\"Genes\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2: get co-expression network of relevant metabolic genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-cell atlas obtained from the HTAN [Chen, Scurrah et al study (2021)](https://doi.org/10.1016/j.cell.2021.11.031). The \"Discovery (DIS) set of human colorectal tumor: Epithelial\" dataset was downloaded in H5AD format from the [Cell x Gene platform](https://cellxgene.cziscience.com/collections/a48f5033-3438-4550-8574-cdff3263fdfd) on 2024-07-24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = ad.read_h5ad('../../data/5bc8d9bb-f6a4-4f7e-add7-2825cbd36625.h5ad')\n",
    "# Replace for concistency with curated pathways\n",
    "atlas.var.feature_name.replace({\"PKM\":\"PKM2\"}, inplace=True)\n",
    "# Keep only the metabolic markers\n",
    "atlas = atlas[:,atlas.var.feature_name.isin(all_metab_gene_symbols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pearson correlation between genes (columns)\n",
    "corrmat = atlas.to_df().corr()\n",
    "corrlist = corrmat.melt(ignore_index=False).reset_index()\n",
    "corrlist = corrlist.loc[corrlist[\"index\"] < corrlist[\"variable\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop low correlations to make the network sparser, but aim to keep at least 80% of the markers in the network\n",
    "corr_thr = 0.03\n",
    "cfilt = corrlist.loc[(corrlist[\"value\"] > corr_thr)|(corrlist[\"value\"] < -corr_thr),:]\n",
    "g = nx.from_pandas_edgelist(cfilt, source=\"index\", target=\"variable\", edge_attr=True)\n",
    "assert nx.number_of_nodes(g) >= 0.8 * atlas.n_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.3: Network diffusion of marker weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import cg  # Conjugate Gradient solver\n",
    "from scipy.sparse import eye, diags\n",
    "\n",
    "def random_walk_with_restart_corrected(g, node_values, r=0.1, precomputed_T=None):\n",
    "    # Ensure node_values is a numpy array\n",
    "    if not isinstance(node_values, np.ndarray):\n",
    "        node_values = np.array(list(node_values.values()))\n",
    "    \n",
    "    # Create a transition probability matrix from the adjacency matrix\n",
    "    # Use precomputed transition matrix if available\n",
    "    if precomputed_T is not None:\n",
    "        T = precomputed_T\n",
    "    else:\n",
    "        A = nx.adjacency_matrix(g)\n",
    "        row_sums = np.array(A.sum(axis=1)).flatten()\n",
    "        row_sums[row_sums == 0] = 1  # Avoid division by zero for isolated nodes\n",
    "        T = A.multiply(1 / row_sums[:, np.newaxis])\n",
    "    \n",
    "    # Identity matrix\n",
    "    I = eye(T.shape[0])\n",
    "    \n",
    "    # Linear system: (I - (1 - r) * T) x = r * v\n",
    "    A = I - (1 - r) * T\n",
    "    b = r * node_values\n",
    "    \n",
    "    # Solve the linear system using Conjugate Gradient method\n",
    "    x, _ = cg(A, b, tol=1e-8, maxiter=1000)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: even with attempts at parallelization, the following cell takes ~n hours (>100 minutes) to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Association between pathway genes and markers\n",
    "gene_to_marker_dict = {\n",
    "    'SLC3A2': 'CD98',\n",
    "    'CYC1': 'CytC',\n",
    "    'SLC16A1': 'MCT1',\n",
    "    'SLC1A5': 'ASCT2',\n",
    "    'LDHA': 'LDH',\n",
    "    'LDHB': 'LDH',\n",
    "    'GLUL': 'GS',\n",
    "    'GLS': 'GLS',\n",
    "    'ATP5A1': 'ATP5A',\n",
    "    'CS': 'CS',\n",
    "    'PKM2': 'PKM2',\n",
    "    'SLC2A1': 'GLUT1',\n",
    "}\n",
    "# Vectorize operations instead of using apply\n",
    "df_ini = adata.obs.loc[adata.obs.consensus == \"Cancer_cell\", metab_markers]\n",
    "df_ini = (df_ini - df_ini.mean())/df_ini.std()\n",
    "# For testing only\n",
    "df_ini = df_ini.sample(30000, random_state=0)\n",
    "\n",
    "symb_dict = atlas.var.feature_name.to_dict()\n",
    "index_to_marker = {i: gene_to_marker_dict[symb_dict[gene_ensg]]\n",
    "                   for i, gene_ensg in enumerate(g.nodes)\n",
    "                   if symb_dict[gene_ensg] in gene_to_marker_dict}\n",
    "\n",
    "def diffused_abundance(g, seed_values, index_to_marker, r=0.1, precomputed_T=None):\n",
    "    initial_values = np.zeros(len(g.nodes))  # Use numpy for initialization\n",
    "    for i, m in index_to_marker.items():\n",
    "        initial_values[i] = seed_values[m]\n",
    "    \n",
    "    final_values_array = random_walk_with_restart_corrected(g, initial_values, r=r, precomputed_T=precomputed_T)\n",
    "    return final_values_array\n",
    "\n",
    "# Precompute RWR transition matrix\n",
    "A = nx.adjacency_matrix(g)\n",
    "row_sums = np.array(A.sum(axis=1)).flatten()\n",
    "row_sums[row_sums == 0] = 1  # Avoid division by zero for isolated nodes\n",
    "T = A.multiply(1 / row_sums[:, np.newaxis])\n",
    "\n",
    "# Parallel processing to speed up diffused_abundance computation\n",
    "# Step 1: Generate list of tuples using Parallel processing\n",
    "results = Parallel(n_jobs=-1)(delayed(lambda i: (df_ini.index[i], diffused_abundance(g=g, seed_values=df_ini.iloc[i], \n",
    "                                                                                     index_to_marker=index_to_marker,\n",
    "                                                                                     precomputed_T=T)))(i) for i in range(df_ini.shape[0]))\n",
    "\n",
    "# Step 2: Convert list of tuples into a dictionary\n",
    "results_dict = dict(results)\n",
    "\n",
    "# Step 3: Create DataFrame from the dictionary\n",
    "df_diff = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[symb_dict[n] for n in g.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.read_csv(\"../../data/diffused_abundance.csv\", index_col=0) # If pre-computed\n",
    "df_diff.index = df_diff.index.astype(str)\n",
    "# df_diff.to_csv(\"diffused_abundance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.4: Compute weighted score from diffused abundance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_pw_dict = {p : {} for p in curated_pw.loc[curated_pw.Pathways.isin(main_pathways.keys()),\"Pathways\"].unique()}\n",
    "# Convert data frame of genes and pathways to a dictionary of genes in each pathway\n",
    "for gene, path in curated_pw.loc[curated_pw.Pathways.isin(main_pathways.keys()),:].values:\n",
    "    if gene in df_diff.columns:\n",
    "        curated_pw_dict[path][gene] = 1.0 # Each gene has a pathway-specific weight, default to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(v, k):\n",
    "    # Get corresponding values and z-score per column\n",
    "    pathway_abundances = df_diff.loc[:,v.keys()]\n",
    "    \n",
    "    # Computed weighted mean based on coefficient of each marker\n",
    "    pathway_abundances = pathway_abundances.apply(lambda x: x*v[x.name], axis = 0)\n",
    "    return(np.sum(pathway_abundances, axis = 1)/sum(v.values()))\n",
    "\n",
    "df_metab3 = pd.DataFrame({k: comp_score(v,k) for k,v in curated_pw_dict.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(\n",
    "    XGBClassifier(\n",
    "        n_estimators=250, \n",
    "        max_depth=3, \n",
    "        device=\"cuda\", \n",
    "        random_state=0),\n",
    "    df_metab3.loc[epithelial_subset].loc[meta.loc[epithelial_subset][\"inner\"]],\n",
    "    LabelEncoder().fit_transform(meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"Stage\"]),\n",
    "    groups=meta.loc[epithelial_subset].loc[meta[\"inner\"]][\"fov\"], \n",
    "    cv=cv_folds, \n",
    "    scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 5: Diffusion of all available markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No marker can be readily added to the diffusion process without rebuilding the network\n",
    "print([x for x in adata.var_names if x in symb_dict.values()])\n",
    "print([x for x in adata.obs.columns[:23] if x in symb_dict.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to explore further the potential of gene network diffusion to complement the raw abundance values, the following steps could be followed:  \n",
    "* Create complete correlation network from atlas\n",
    "* Convert to cost ($1 - |\\rho |$)\n",
    "* Compute shortest path between seed nodes and corresponding betweeness centrality per edge\n",
    "* Delete all null-weight edges and any resulting connected component that does not include any seed node. All remaining connected component should have at least two seed nodes\n",
    "* Use backboning / thresholding in each connected component\n",
    "* Do diffusion of abundance from seed nodes\n",
    "* Use all diffused node values as input to an XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following resource could be explored to study protein-metabolite associations:\n",
    "\n",
    "```R\n",
    "library(cosmosR)\n",
    "data(meta_network)\n",
    "```\n",
    "\n",
    "```\n",
    "#' @format An object of class \\dQuote{\\code{tibble}} with 117065 rows\n",
    "#'   (interactions) and three variables:\n",
    "#'   \\describe{\n",
    "#'     \\item{\\code{source}}{Source node, either metabolite or protein}\n",
    "#'     \\item{\\code{interaction}}{Type of interaction, 1 = Activation, -1 = Inhibition}\n",
    "#'     \\item{\\code{target}}{Target node, either metabolite or protein}\n",
    "#'   A detailed description of the identifier formatting can be found under \n",
    "#'   \\url{https://metapkn.omnipathdb.org/00__README.txt}.\n",
    "#'   }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glycolysis**: GLUT1, PKM2, LDH, MCT1  \n",
    "**Fatty acid oxidation**: CPT1A  \n",
    "**TCA cycle**: CS  \n",
    "**Amino acid metabolism**: ARG1, CD98, GLS, GS, ASCT2  \n",
    "**OxPhos**: CytC, ATP5A  \n",
    "**Cancer and proliferation**:CA9, Ki67  \n",
    "\n",
    "In curated list:  \n",
    "**Glycolysis and Gluconeogenesis**: PKM2, LDH (LDHA, LDHB), GLUT1 (SLC2A1), MCT1 (SLC16A1)  \n",
    "**Carnitine shuttle**: CPT1A  \n",
    "**Citric Acid Cycle**: CS, MCT1  \n",
    "**Urea Cycle**: ARG1  \n",
    "**Glutamate metabolism**: CD98 (SLC3A2), GLS, GS (GLUL), ASCT2 (SLC1A5)  \n",
    "**Transport, Extracellular**: CD98  \n",
    "**Glycine, Serine and Threonine Metabolism**: ASCT2  \n",
    "**Valine, Leucine and Isoleucine Metabolism**: ASCT2, MCT1  \n",
    "**Alanine and Aspartate Metabolism**: ASCT2  \n",
    "**Cysteine Metabolism**: ASCT2  \n",
    "**Oxidative Phosphorylation**: CytC (CYC1?), ATP5A (ATP5A1?)  \n",
    "**Carbonic Acid Metabolism**: CA9  \n",
    "**Transport, Golgi Apparatus**: GLUT1  \n",
    "**Biotin Metabolism**: MCT1  \n",
    "**Ketone Bodies Metabolism**: MCT1  \n",
    "**Propanoate Metabolism**: MCT1  \n",
    "\n",
    "Missing Ki67. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pam-keras3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
