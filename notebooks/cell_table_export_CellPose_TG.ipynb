{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is derived from *1_Segment_Image_Data.ipynb* provided by the ark-analysis package. This is a notebook to extract marker counts and morphological information from all the cells in your images based on CellPose segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install alpineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "import"
    ]
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Error: Ark requires Python 3.10 or later.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Error: Ark requires Python 3.10 or later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import xarray as xr\n",
    "from alpineer import io_utils\n",
    "\n",
    "from ark.segmentation import marker_quantification, segmentation_utils\n",
    "from ark.utils import (deepcell_service_utils, example_dataset,\n",
    "                       plot_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Set root directory and download example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder.\n",
    "\n",
    "* `base_dir`: the path to all of your imaging data. This directory will contain all of the data generated by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "base_dir"
    ]
   },
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = \"../data/SMP2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to test the features in Ark with an example dataset, run the cell below. It will download a dataset consisting of 11 FOVs with 22 channels. You may find more information about the example dataset in the [README](../README.md#example-dataset).\n",
    "\n",
    "If you are using your own data, skip the cell below.\n",
    "\n",
    "* `overwrite_existing`: If set to `False`, it will not overwrite existing data in the `data/example_dataset`. Recommended leaving as `True` if you are doing a clean run of the `ark` pipeline using this dataset from the start. If you already have the dataset downloaded, set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ex_data_download"
    ]
   },
   "outputs": [],
   "source": [
    "#example_dataset.get_example_dataset(dataset=\"segment_image_data\", save_dir = base_dir, overwrite_existing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: set file paths and parameters\n",
    "\n",
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n",
    "\n",
    "If you're interested in directly interfacing with Google Drive, consult the documentation [here](https://ark-analysis.readthedocs.io/en/latest/_rtd/google_docs_usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "file_path"
    ]
   },
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
    "cell_table_dir = os.path.join(base_dir, \"segmentation/cell_table\")\n",
    "deepcell_input_dir = os.path.join(base_dir, \"segmentation/cellpose_input\")\n",
    "deepcell_output_dir = os.path.join(base_dir, \"segmentation/cellpose_output\")\n",
    "deepcell_visualization_dir = os.path.join(base_dir, \"segmentation/cellpose_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "create_dirs"
    ]
   },
   "outputs": [],
   "source": [
    "# create directories if do not exist\n",
    "for directory in [cell_table_dir, deepcell_input_dir, deepcell_output_dir, deepcell_visualization_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "validate_path"
    ]
   },
   "outputs": [],
   "source": [
    "# validate paths\n",
    "io_utils.validate_paths([base_dir,\n",
    "                         tiff_dir,\n",
    "                         deepcell_input_dir,\n",
    "                         deepcell_output_dir,\n",
    "                         cell_table_dir,\n",
    "                         deepcell_visualization_dir\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and filter fov paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "load_fovs"
    ]
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov0\", \"fov1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2: Image export and value computing\n",
    "### We can then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "overlay_mask"
    ]
   },
   "outputs": [],
   "source": [
    "# display the channel overlay for a fov, useful for quick verification\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "fov_to_display = io_utils.remove_file_extensions([fovs[0]])[0]\n",
    "\n",
    "fov_overlay = plot_utils.create_overlay(\n",
    "    fov=fov_to_display,\n",
    "    segmentation_dir=deepcell_output_dir,\n",
    "    data_dir=deepcell_input_dir,\n",
    "    img_overlay_chans=['nuclear_channel', 'membrane_channel'],\n",
    "    seg_overlay_comp='whole_cell'\n",
    ")\n",
    "\n",
    "_ = io.imshow(fov_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save_mask"
    ]
   },
   "outputs": [],
   "source": [
    "# save the overlaid segmentation labels for each fov (these will not display, but will save in viz_dir)\n",
    "segmentation_utils.save_segmentation_labels(\n",
    "    segmentation_dir=deepcell_output_dir,\n",
    "    data_dir=deepcell_input_dir,\n",
    "    output_dir=deepcell_visualization_dir,\n",
    "    fovs=io_utils.remove_file_extensions(fovs),\n",
    "    channels=['nuclear_channel', 'membrane_channel']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nuc_props_set"
    ]
   },
   "outputs": [],
   "source": [
    "# set to True to add nuclear cell properties to the expression matrix\n",
    "nuclear_counts = False\n",
    "\n",
    "# set to True to bypass expensive cell property calculations\n",
    "# only cell label, size, and centroid will be extracted if True\n",
    "fast_extraction = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full list of features extracted, please refer to the cell table section of: https://ark-analysis.readthedocs.io/en/latest/_rtd/data_types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "create_exp_mat"
    ]
   },
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given its own folder and all fovs having the same channels\n",
    "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "    marker_quantification.generate_cell_table(segmentation_dir=deepcell_output_dir,\n",
    "                                              tiff_dir=tiff_dir,\n",
    "                                              img_sub_folder=None,\n",
    "                                              fovs=fovs,\n",
    "                                              batch_size=5,\n",
    "                                              nuclear_counts=nuclear_counts,\n",
    "                                              fast_extraction=fast_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_table_size_normalized = cell_table_size_normalized.loc[cell_table_size_normalized.nuclei>0,:]\n",
    "cell_table_arcsinh_transformed = cell_table_arcsinh_transformed.loc[cell_table_arcsinh_transformed.nuclei>0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save_exp_mat"
    ]
   },
   "outputs": [],
   "source": [
    "# Set the compression level if desired, ZSTD compression can offer up to a 60-70% reduction in file size.\n",
    "# NOTE: Compressed `csv` files cannot be opened in Excel. They must be uncompressed beforehand.\n",
    "compression = None\n",
    "\n",
    "# Uncomment the line below to allow for compressed `csv` files.\n",
    "# compression = {\"method\": \"zstd\", \"level\": 3}\n",
    "\n",
    "cell_table_size_normalized.to_csv(os.path.join(cell_table_dir, 'cell_table_size_normalized.csv'),\n",
    "                                  compression=compression, index=False)\n",
    "cell_table_arcsinh_transformed.to_csv(os.path.join(cell_table_dir, 'cell_table_arcsinh_transformed.csv'),\n",
    "                                      compression=compression, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cd428f2623867f362c6ffd1805d28fe273bb79d15f4a3a73107e7f51d98be79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
